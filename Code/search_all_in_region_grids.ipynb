{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cb1162e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Auto-reload modules when they change (useful for development)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pyairbnb\n",
    "from pyairbnb import search_all, get_calendar\n",
    "from datetime import date, datetime, timedelta\n",
    "import calendar\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83dbce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* Load the grid json files\n",
    "\"\"\"\n",
    "def load_grid_json_files(folder_path):\n",
    "    data_list = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.startswith(\"grid_\") and filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# * Get the last day of the next month\n",
    "# \"\"\"\n",
    "# def get_the_last_day_of_next_month():\n",
    "#     month = today.month + 1\n",
    "#     year = today.year + (month - 1) // 12\n",
    "#     month = ((month - 1) % 12) + 1\n",
    "\n",
    "#     last_day = calendar.monthrange(year, month)[1]\n",
    "#     return date(year, month, last_day)\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# * Get the last day of the next next months\n",
    "# \"\"\"\n",
    "# def get_the_last_day_of_next_two_months():\n",
    "#     month = today.month + 2\n",
    "#     year = today.year + (month - 1) // 12\n",
    "#     month = ((month - 1) % 12) + 1\n",
    "\n",
    "#     last_day = calendar.monthrange(year, month)[1]\n",
    "#     return date(year, month, last_day)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "* Output the number of remaining days in a specific month of a specific year (including the given day)\n",
    "\"\"\"\n",
    "def number_of_days_until_end_of_month(day, month, year):\n",
    "    current_date = date(year, month, day)\n",
    "    \n",
    "    # Find the first day of the next month\n",
    "    if month == 12:\n",
    "        next_month = date(year + 1, 1, 1)\n",
    "    else:\n",
    "        next_month = date(year, month + 1, 1)\n",
    "    \n",
    "    # Last day of the current month\n",
    "    last_day_of_month = next_month - timedelta(days=1)\n",
    "    \n",
    "    # Difference in days (include today)\n",
    "    delta = last_day_of_month - current_date\n",
    "    return delta.days + 1\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "* Output the available days in a month\n",
    "\"\"\"\n",
    "def get_available_dates(calendar_month):\n",
    "    month = calendar_month['month']\n",
    "    year = calendar_month['year'] \n",
    "    days_info = calendar_month['days']\n",
    "\n",
    "    available_dates_next30days_list = []\n",
    "\n",
    "    for day_info in days_info:\n",
    "        available_today = day_info['availableForCheckin'] | day_info['availableForCheckout']\n",
    "        if available_today:\n",
    "            date_str = day_info['calendarDate']\n",
    "            day = datetime.strptime(date_str, \"%Y-%m-%d\").day\n",
    "            available_dates_next30days_list.append(day)\n",
    "\n",
    "    return np.array(available_dates_next30days_list)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "* Analyze the reviews of a listing and find missing months of each year\n",
    "\n",
    "Resolved issue: \n",
    "There are instances where is generalized review date (eg. 2 weeks ago) shown on the listing is not the actual review date.\n",
    "Example: found on https://www.airbnb.com/rooms/8133168\n",
    "Review date: 2025-11-30T22:29:47Z\n",
    "Generalized review date: Il y a 2 semaines\n",
    "Time when I debug this issue : 2025-12-21 2:00 AM\n",
    "\n",
    "Reason :\n",
    "2 weeks after the review date should be 2025-12-21T22:29:47Z. It hasn't reach that time yet. Therefore, it's shown as 2 weeks ago.\n",
    "\n",
    "Conclusion: \n",
    "The current code is correct. No change is needed.\n",
    "\"\"\"\n",
    "def analyze_reviews(room_id):\n",
    "    room_url = f\"https://www.airbnb.com.sg/rooms/{room_id}\"\n",
    "    proxy_url = \"\"  # Proxy URL (if needed)\n",
    "    language = \"fr\"\n",
    "\n",
    "    reviews_data = pyairbnb.get_reviews(room_url, language, proxy_url)\n",
    "\n",
    "    review_analysis = {}\n",
    "\n",
    "    for review in reviews_data:\n",
    "        reviw_date = datetime.fromisoformat(review['createdAt'].replace('Z', '+00:00'))\n",
    "        month = int(reviw_date.month)\n",
    "        year = int(reviw_date.year)\n",
    "        # comment = review['comments']\n",
    "        # rating = review['rating']\n",
    "\n",
    "        if year not in review_analysis:\n",
    "            review_analysis[year] = set()\n",
    "\n",
    "        review_analysis[year].add(month)\n",
    "\n",
    "\n",
    "    all_month = set([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "    for year, month_set in review_analysis.items():\n",
    "        missing_months = sorted(all_month - month_set)\n",
    "        # if missing_months:\n",
    "        #     print(f\"Year {year} is missing months: {missing_months}\")\n",
    "        # else:\n",
    "        #     print(f\"Year {year} has all months !\")\n",
    "\n",
    "    return review_analysis\n",
    "\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# * Check if the 75 rule is met\n",
    "# \"\"\"\n",
    "# def check_75_rule(\n",
    "#     curr_month_available_dates, \n",
    "#     next_month_available_dates,\n",
    "#     leniency=2\n",
    "# ):\n",
    "#     next_30th_day = today + timedelta(days=30)\n",
    "#     next_mask = next_month_available_dates < next_30th_day.day\n",
    "#     available_days_next30days = len(curr_month_available_dates) + len(next_month_available_dates[next_mask])\n",
    "#     days_booked = 30 - available_days_next30days\n",
    "#     if days_booked > 22 - leniency:\n",
    "#         return True, days_booked\n",
    "#     return False, None\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# * Check if the 55 rule is met\n",
    "# \"\"\"\n",
    "# def check_55_rule(\n",
    "#     next_month_available_dates,\n",
    "#     next_two_months_available_dates,\n",
    "#     leniency=2\n",
    "# ):\n",
    "#     next_30th_day = today + timedelta(days=30)\n",
    "#     next_next_30th_day = today + timedelta(days=60)\n",
    "#     next_mask_remains = next_month_available_dates >= next_30th_day.day\n",
    "#     next_next_mask = next_two_months_available_dates < next_next_30th_day.day\n",
    "#     available_days_nextnext30days = len(next_month_available_dates[next_mask_remains]) + len(next_two_months_available_dates[next_next_mask]) \n",
    "#     days_booked = 30 - available_days_nextnext30days\n",
    "#     if days_booked > 17 - leniency:\n",
    "#         return True, days_booked\n",
    "#     return False, None\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "* Check if the reviews count is sufficient\n",
    "\"\"\"\n",
    "def check_reviews_count(review_months_this_year, review_months_last_year, leniency):\n",
    "    warning_level = None\n",
    "    warning_type = None\n",
    "    warning_message = None\n",
    "\n",
    "    condition_1 = len(review_months_this_year) < today.month - leniency\n",
    "    condition_2 = len(review_months_last_year) < (12 - leniency)\n",
    "\n",
    "    if (condition_1 and condition_2):\n",
    "        warning_level = \"High\"\n",
    "        warning_type = \"Insufficient months of reviews this year and last year\"\n",
    "        warning_message = f\"This listing has only {len(review_months_this_year)} months of reviews this year and {len(review_months_last_year)} months of reviews last year\"\n",
    "\n",
    "    elif condition_1:\n",
    "        warning_level = \"High\"\n",
    "        warning_type = \"Insufficient months of reviews this year\"\n",
    "        warning_message = f\"This listing has only {len(review_months_this_year)} months of reviews this year.\"\n",
    "    \n",
    "    elif condition_2:\n",
    "        warning_level = \"High\"\n",
    "        warning_type = \"Insufficient months of reviews last year\"\n",
    "        warning_message = f\"This listing has only {len(review_months_last_year)} months of reviews last year.\"\n",
    "\n",
    "    return warning_level, warning_type, warning_message\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_grid_for_coordinate(lat, lon):\n",
    "    \"\"\"\n",
    "    Given a latitude and longitude, find which grid cell (by grid_id)\n",
    "    the coordinate falls into, based on the bounding box definitions\n",
    "    in gird_coords_df.\n",
    "    \n",
    "    Parameters:\n",
    "        lat (float): Latitude of the point.\n",
    "        lon (float): Longitude of the point.\n",
    "        gird_coords_df (pd.DataFrame): DataFrame containing columns:\n",
    "            ['grid_id', 'ne_lat', 'ne_long', 'sw_lat', 'sw_long']\n",
    "    \n",
    "    Returns:\n",
    "        int or None: grid_id of the matching grid, or None if outside.\n",
    "    \"\"\"\n",
    "    match = gird_coords_df[\n",
    "        (gird_coords_df['sw_lat'] <= lat) & (lat <= gird_coords_df['ne_lat']) &\n",
    "        (gird_coords_df['sw_long'] <= lon) & (lon <= gird_coords_df['ne_long'])\n",
    "    ]\n",
    "    \n",
    "    if not match.empty:\n",
    "        return int(match.iloc[0]['grid_id'])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "* Add a summary row to the summary DataFrame\n",
    "\"\"\"\n",
    "def add_summary_row(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    room_id=None,\n",
    "    listing_url=None,\n",
    "    next_30_days_booked_days=None,\n",
    "    next_30_to_60_days_booked_days=None,\n",
    "    rule_75_met: bool = False,\n",
    "    rule_55_met: bool = False,\n",
    "    warning_level=None,\n",
    "    warning_type=None,\n",
    "    warning_message=None,\n",
    "    rating=None,\n",
    "    review_count=None,\n",
    "    review_months_this_year=None,\n",
    "    review_months_last_year=None,\n",
    "    missing_review_months_this_year=None,\n",
    "    missing_review_months_last_year=None,\n",
    "    total_missing_review_months_this_year=None,\n",
    "    total_missing_review_months_last_year=None,\n",
    "    latitiude=None,\n",
    "    longitude=None,\n",
    "    grid_index=None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Append a single summary row to the provided DataFrame and return the new DataFrame.\n",
    "    List-like fields default to empty lists; scalar fields default to NaN/False if not provided.\n",
    "    \"\"\"\n",
    "    row = {\n",
    "        'Room_id': room_id,\n",
    "        'Listing_url': listing_url,\n",
    "        \n",
    "        'Next_30_days_booked_days': next_30_days_booked_days,\n",
    "        'Next_30_to_60_days_booked_days': next_30_to_60_days_booked_days,\n",
    "\n",
    "        '75_rule_met': bool(rule_75_met),\n",
    "        '55_rule_met': bool(rule_55_met),\n",
    "\n",
    "        'Warning_level': warning_level,\n",
    "        'Warning_type': warning_type,\n",
    "        'Warning_message': warning_message,\n",
    "\n",
    "        'Rating': rating,\n",
    "        'Review_count': review_count,\n",
    "\n",
    "        'Review_months_this_year': review_months_this_year if review_months_this_year is not None else [],\n",
    "        'Review_months_last_year': review_months_last_year if review_months_last_year is not None else [],\n",
    "        'Missing_review_months_this_year': missing_review_months_this_year if missing_review_months_this_year is not None else [],\n",
    "        'Missing_review_months_last_year': missing_review_months_last_year if missing_review_months_last_year is not None else [],\n",
    "        'Total_missing_review_months_this_year': total_missing_review_months_this_year,\n",
    "        'Total_missing_review_months_last_year': total_missing_review_months_last_year,\n",
    "\n",
    "        'Latitiude': latitiude,\n",
    "        'Longitude': longitude,\n",
    "        'Grid_index': grid_index,\n",
    "    }\n",
    "\n",
    "    # Ensure all DataFrame columns exist before concat; create any missing columns with NaN/False defaults\n",
    "    for col in row.keys():\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan if col not in ['75_rule_met', '55_rule_met', 'Review_missing_months_this_year', 'Review_missing_months_last_year'] else (False if 'rule' in col else [])\n",
    "\n",
    "    # Use concat to avoid SettingWithCopy warnings and to keep types consistent\n",
    "    new_df = pd.concat([df, pd.DataFrame([row], columns=df.columns)], ignore_index=True)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_configuration(configuration):\n",
    "    guest_count = 0\n",
    "    bedroom_count = 0\n",
    "    bed_count = 0\n",
    "    bath_count = 0\n",
    "\n",
    "    for config in configuration:\n",
    "        if \"guest\" in config:\n",
    "            num = str(config.split(\" \")[0])\n",
    "        elif \"bedroom\" in config:\n",
    "            bedroom_count = str(config.split(\" \")[0])\n",
    "        elif \"bed\" in config:\n",
    "            bed_count = str(config.split(\" \")[0])\n",
    "        elif \"bath\" in config:\n",
    "            bath_count = str(config.split(\" \")[0])\n",
    "\n",
    "    return guest_count, bedroom_count, bed_count, bath_count\n",
    "\n",
    "\n",
    "def get_review_count_by_year_and_month(reviews):\n",
    "    \"\"\"\n",
    "    {2025: [3, 4, 7, 5, 6, 7, 9, 6, 7, 6, 6, 5],\n",
    "    2024: [4, 5, 3, 7, 8, 5, 5, 4, 8, 7, 10, 4],\n",
    "    2023: [10, 7, 8, 8, 7, 10, 9, 7, 5, 11, 7, 6],\n",
    "    2022: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5]}\n",
    "    \"\"\"\n",
    "    review_dict = {}\n",
    "    for each_review in reviews:    \n",
    "        createdAt_str = each_review['createdAt']\n",
    "        createdAt_dt = datetime.fromisoformat(createdAt_str.replace('Z', '+00:00'))\n",
    "        year = createdAt_dt.year\n",
    "        month = createdAt_dt.month\n",
    "        \n",
    "        if year not in review_dict:\n",
    "            review_dict[year] = [0] * 12  # 12 months, all start at 0\n",
    "        \n",
    "        review_dict[year][month - 1] += 1\n",
    "\n",
    "    return review_dict\n",
    "\n",
    "\n",
    "def get_available_dates_by_year_and_month(data):\n",
    "    availability_dict = {}\n",
    "\n",
    "    for each_month_info in data['calendar']:\n",
    "        month = each_month_info['month']\n",
    "        year = each_month_info['year']\n",
    "        days = each_month_info['days']\n",
    "        \n",
    "        # Initialize year if not exists\n",
    "        if year not in availability_dict:\n",
    "            availability_dict[year] = {}\n",
    "        \n",
    "        # Initialize month if not exists\n",
    "        if month not in availability_dict[year]:\n",
    "            availability_dict[year][month] = []\n",
    "        \n",
    "        # Collect available days in this month\n",
    "        for day in days:\n",
    "            date = day['calendarDate']\n",
    "            available_checkin = day['availableForCheckin']\n",
    "            available_checkout = day['availableForCheckout']\n",
    "            \n",
    "            if available_checkin or available_checkout:\n",
    "                # Extract day number from date (e.g., \"2025-01-15\" -> 15)\n",
    "                day_number = int(date.split('-')[2])\n",
    "                availability_dict[year][month].append(day_number)\n",
    "\n",
    "    return availability_dict\n",
    "\n",
    "\n",
    "\n",
    "def count_available_days_in_range(available_dates_dict, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Count how many days are available in a date range.\n",
    "    \n",
    "    Args:\n",
    "        available_dates_dict: {'year': {'month': [day1, day2, ...]}}\n",
    "        year: str\n",
    "        month: str\n",
    "        day: int\n",
    "        start_date: datetime.date object\n",
    "        end_date: datetime.date object (inclusive)\n",
    "    \n",
    "    Returns:\n",
    "        int: Number of available days in the range\n",
    "    \"\"\"\n",
    "    if not isinstance(available_dates_dict, dict) or not available_dates_dict:\n",
    "        return None\n",
    "    \n",
    "    available_count = 0\n",
    "    current_date = start_date\n",
    "    \n",
    "    while current_date <= end_date:\n",
    "        year = int(current_date.year)   # String\n",
    "        month = int(current_date.month) # String\n",
    "        day = current_date.day          # Int\n",
    "        \n",
    "        # Check if this date is in the available dates dictionary\n",
    "        if year in available_dates_dict:\n",
    "            if month in available_dates_dict[year]:\n",
    "                if day in available_dates_dict[year][month]:\n",
    "                    available_count += 1\n",
    "        current_date += timedelta(days=1)\n",
    "    \n",
    "    return available_count\n",
    "\n",
    "\n",
    "def get_available_dates_75Rule(available_dates_dict):\n",
    "    start_date = date.today()\n",
    "    end_date = date.today() + timedelta(days=29)  # Days 0-29 (30 days total)\n",
    "    available_count = count_available_days_in_range(available_dates_dict, start_date, end_date)\n",
    "    return available_count\n",
    "\n",
    "\n",
    "def get_available_dates_55Rule(available_dates_dict):\n",
    "    today = date.today()\n",
    "    start_date = today + timedelta(days=30)  # Day 30\n",
    "    end_date = today + timedelta(days=59)    # Day 59 (30 days total)\n",
    "    available_count = count_available_days_in_range(available_dates_dict, start_date, end_date)\n",
    "    return available_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6e5ef6",
   "metadata": {},
   "source": [
    "# Step 0: Extract the grid coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "186041c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(273, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_name = \"Above-San-Franciso\"\n",
    "\n",
    "grid_start_index_list = [1, 31, 61, 91, 121, 151, 181, 211, 241, 271]\n",
    "grid_end_index_list = [30, 60, 90, 120, 150, 180, 210, 240, 270, 273]\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################################################\n",
    "\n",
    "\n",
    "gird_coords_df = pd.DataFrame()\n",
    "for grid_start_index, grid_end_index in zip(grid_start_index_list, grid_end_index_list):\n",
    "    grid_filename = f\"{region_name}_full_safe_grid{grid_start_index}_to_grid{grid_end_index}_rows.xlsx\"\n",
    "\n",
    "    each_gird_coords_df = pd.read_excel(f\"../Grid-Coords-Files/{region_name}/{grid_filename}\")\n",
    "    gird_coords_df = pd.concat([gird_coords_df, each_gird_coords_df])\n",
    "\n",
    "gird_coords_df = gird_coords_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "gird_coords_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85a199a",
   "metadata": {},
   "source": [
    "# Step 1: Discovery Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "872e892e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_grids = [\n",
    "    4, 5, 6,\n",
    "    7, 8, 9, 10, \n",
    "    17, 18, 19, 20, 21,\n",
    "    28, 29,\n",
    "    38, 39, 40, 41, 42,\n",
    "    48, 49, 50, 51, \n",
    "    58, 59, 60, 61, 62, 63,\n",
    "    69, 70, 71, 72, 73, 79, 80, 81, 82, 83, 84,\n",
    "    90, 91, 92, 93,\n",
    "    112,\n",
    "    174,\n",
    "    217, 218,\n",
    "    232, 237, 238, 239, 240, \n",
    "    253, 254, 258, 259, 260, 261\n",
    "]\n",
    "\n",
    "gird_coords_df.shape[0] - len(skip_grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8230c7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamingleung/Development/TryOut/Airbnb-Search/Code/discovery.py:133: UserWarning: ‚ö†Ô∏è  Using specific dates for discovery may miss listings that are booked on those dates. Consider setting use_blank_dates=True for complete discovery.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Starting improved discovery system...\n",
      "Region: Above-San-Franciso\n",
      "Grid cells to search: 273\n",
      "‚è≠Ô∏è  Grids to skip: [4, 5, 6, 7, 8, 9, 10, 17, 18, 19, 20, 21, 28, 29, 38, 39, 40, 41, 42, 48, 49, 50, 51, 58, 59, 60, 61, 62, 63, 69, 70, 71, 72, 73, 79, 80, 81, 82, 83, 84, 90, 91, 92, 93, 112, 174, 217, 218, 232, 237, 238, 239, 240, 253, 254, 258, 259, 260, 261]\n",
      "Grids to process: 214\n",
      "Discovery passes per cell: 30\n",
      "üìù Detailed logs will be saved to: Discovery-Search-Logs/\n",
      "======================================================================\n",
      "‚è≠Ô∏è  Skipping 59 grids: [4, 5, 6, 7, 8, 9, 10, 17, 18, 19, 20, 21, 28, 29, 38, 39, 40, 41, 42, 48, 49, 50, 51, 58, 59, 60, 61, 62, 63, 69, 70, 71, 72, 73, 79, 80, 81, 82, 83, 84, 90, 91, 92, 93, 112, 174, 217, 218, 232, 237, 238, 239, 240, 253, 254, 258, 259, 260, 261]\n",
      "\n",
      "üìç Processing grid 1 of 273...\n",
      "\n",
      "üìç Processing grid 2 of 273...\n",
      "\n",
      "üìç Processing grid 3 of 273...\n",
      "‚è≠Ô∏è  Skipping grid 4 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 5 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 6 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 7 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 8 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 9 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 10 (in skip list)\n",
      "\n",
      "üìç Processing grid 11 of 273...\n",
      "\n",
      "üìç Processing grid 12 of 273...\n",
      "\n",
      "üìç Processing grid 13 of 273...\n",
      "\n",
      "üìç Processing grid 14 of 273...\n",
      "\n",
      "üìç Processing grid 15 of 273...\n",
      "\n",
      "üìç Processing grid 16 of 273...\n",
      "‚è≠Ô∏è  Skipping grid 17 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 18 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 19 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 20 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 21 (in skip list)\n",
      "\n",
      "üìç Processing grid 22 of 273...\n",
      "\n",
      "üìç Processing grid 23 of 273...\n",
      "\n",
      "üìç Processing grid 24 of 273...\n",
      "\n",
      "üìç Processing grid 25 of 273...\n",
      "\n",
      "üìç Processing grid 26 of 273...\n",
      "\n",
      "üìç Processing grid 27 of 273...\n",
      "‚è≠Ô∏è  Skipping grid 28 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 29 (in skip list)\n",
      "\n",
      "üìç Processing grid 30 of 273...\n",
      "\n",
      "üìç Processing grid 31 of 273...\n",
      "\n",
      "üìç Processing grid 32 of 273...\n",
      "\n",
      "üìç Processing grid 33 of 273...\n",
      "\n",
      "üìç Processing grid 34 of 273...\n",
      "\n",
      "üìç Processing grid 35 of 273...\n",
      "\n",
      "üìç Processing grid 36 of 273...\n",
      "\n",
      "üìç Processing grid 37 of 273...\n",
      "‚è≠Ô∏è  Skipping grid 38 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 39 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 40 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 41 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 42 (in skip list)\n",
      "\n",
      "üìç Processing grid 43 of 273...\n",
      "\n",
      "üìç Processing grid 44 of 273...\n",
      "\n",
      "üìç Processing grid 45 of 273...\n",
      "\n",
      "üìç Processing grid 46 of 273...\n",
      "\n",
      "üìç Processing grid 47 of 273...\n",
      "‚è≠Ô∏è  Skipping grid 48 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 49 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 50 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 51 (in skip list)\n",
      "\n",
      "üìç Processing grid 52 of 273...\n",
      "\n",
      "üìç Processing grid 53 of 273...\n",
      "\n",
      "üìç Processing grid 54 of 273...\n",
      "\n",
      "üìç Processing grid 55 of 273...\n",
      "\n",
      "üìç Processing grid 56 of 273...\n",
      "\n",
      "üìç Processing grid 57 of 273...\n",
      "‚è≠Ô∏è  Skipping grid 58 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 59 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 60 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 61 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 62 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 63 (in skip list)\n",
      "\n",
      "üìç Processing grid 64 of 273...\n",
      "\n",
      "üìç Processing grid 65 of 273...\n",
      "\n",
      "üìç Processing grid 66 of 273...\n",
      "\n",
      "üìç Processing grid 67 of 273...\n",
      "\n",
      "üìç Processing grid 68 of 273...\n",
      "‚è≠Ô∏è  Skipping grid 69 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 70 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 71 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 72 (in skip list)\n",
      "‚è≠Ô∏è  Skipping grid 73 (in skip list)\n",
      "\n",
      "üìç Processing grid 74 of 273...\n",
      "\n",
      "üìç Processing grid 75 of 273...\n",
      "\n",
      "üìç Processing grid 76 of 273...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from discovery import discover_all_grids, DiscoveryConfig, BBox, AirbnbDiscoveryEngine\n",
    "\n",
    "# Configure discovery parameters\n",
    "discovery_config = DiscoveryConfig(\n",
    "    # Rate limiting (conservative to avoid bans)\n",
    "    requests_per_minute=10,\n",
    "    \n",
    "    # Subdivision strategy\n",
    "    max_results_before_subdivide=280,\n",
    "    min_bbox_size_degrees=0.001,\n",
    "    max_subdivision_depth=4,\n",
    "    \n",
    "    # Multi-pass strategy\n",
    "    num_discovery_passes = 30,\n",
    "    use_blank_dates=False,\n",
    "    \n",
    "    alternate_checkin_offsets=[None, 3, 7, 14, 30, 60, 90],\n",
    "    alternate_stay_nights=[1, 2, 3],\n",
    "    alternate_zoom_values=[14, 15, 16],\n",
    "\n",
    "    # User-agent rotation\n",
    "    rotate_user_agents=True,\n",
    "    \n",
    "    # Search parameters\n",
    "    price_min=250,\n",
    "    price_max=10000,\n",
    "    currency=\"USD\",\n",
    "    \n",
    "    # Caching\n",
    "    cache_dir=f\"Data/{region_name}/discovery_cache\",\n",
    "    enable_cache=False,\n",
    "    \n",
    "    # Logging (to prevent notebook lag)\n",
    "    log_to_file=True,\n",
    "    log_dir=\"Discovery-Search-Logs\",\n",
    "    log_level=\"INFO\",\n",
    "    \n",
    "    # Stats\n",
    "    stats_file=f\"Data/{region_name}/discovery_stats.json\",\n",
    ")\n",
    "\n",
    "print(\"üîç Starting improved discovery system...\")\n",
    "print(f\"Region: {region_name}\")\n",
    "print(f\"Grid cells to search: {len(gird_coords_df)}\")\n",
    "if len(skip_grids) > 0:\n",
    "    print(f\"‚è≠Ô∏è  Grids to skip: {skip_grids}\")\n",
    "    print(f\"Grids to process: {len(gird_coords_df) - len(skip_grids)}\")\n",
    "print(f\"Discovery passes per cell: {discovery_config.num_discovery_passes}\")\n",
    "print(f\"üìù Detailed logs will be saved to: {discovery_config.log_dir}/\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Run discovery with skip list\n",
    "discovered_listings, engine = discover_all_grids(\n",
    "    gird_coords_df, \n",
    "    region_name, \n",
    "    discovery_config,\n",
    "    skip_grids=skip_grids  # ‚≠ê NEW: Pass the skip list\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Discovery complete!\")\n",
    "print(f\"üìä Total unique listings: {len(discovered_listings)}\")\n",
    "print(f\"üìÅ Saved to: Data/{region_name}/discovered_listings.json\")\n",
    "print(f\"üìà Stats saved to: {discovery_config.stats_file}\")\n",
    "\n",
    "# Convert for enrichment\n",
    "all_results = [listing.raw_data for listing in discovered_listings.values()]\n",
    "print(f\"\\n‚úì Ready for enrichment pipeline with {len(all_results)} listings\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # OPTION A: USE IMPROVED DISCOVERY SYSTEM (RECOMMENDED)\n",
    "# # ============================================================================\n",
    "\n",
    "# from discovery import discover_all_grids, DiscoveryConfig, BBox, AirbnbDiscoveryEngine\n",
    "\n",
    "# # Configure discovery parameters\n",
    "# discovery_config = DiscoveryConfig(\n",
    "#     # Rate limiting (conservative to avoid bans)\n",
    "#     requests_per_minute=10,\n",
    "    \n",
    "#     # Subdivision strategy\n",
    "#     max_results_before_subdivide=280,  # Subdivide if we hit ~280+ results (likely capped)\n",
    "#     min_bbox_size_degrees=0.001,  # Stop subdividing below ~100m\n",
    "#     max_subdivision_depth=4,\n",
    "    \n",
    "#     # Multi-pass strategy (catches rotated listings)\n",
    "#     num_discovery_passes = 30,\n",
    "#     use_blank_dates=False,\n",
    "    \n",
    "#     alternate_checkin_offsets=[None, 3, 7, 14, 30, 60, 90],  # Try +14, +21, +30 days ahead\n",
    "#     alternate_stay_nights=[1, 2, 3],  # Stay lengths \n",
    "#     alternate_zoom_values=[14, 15, 16],  # Zoom levels\n",
    "\n",
    "#     # User-agent rotation (anti-detection)\n",
    "#     rotate_user_agents=True,\n",
    "    \n",
    "#     # Search parameters\n",
    "#     price_min=250,\n",
    "#     price_max=10000,\n",
    "#     currency=\"USD\",\n",
    "    \n",
    "#     # Caching for resume capability\n",
    "#     cache_dir=f\"Data/{region_name}/discovery_cache\",\n",
    "#     enable_cache=False,\n",
    "    \n",
    "#     # Stats output\n",
    "#     stats_file=f\"Data/{region_name}/discovery_stats.json\",\n",
    "# )\n",
    "\n",
    "# print(\"üîç Starting improved discovery system...\")\n",
    "# print(f\"Region: {region_name}\")\n",
    "# print(f\"Grid cells to search: {len(gird_coords_df)}\")\n",
    "# print(f\"Discovery passes per cell: {discovery_config.num_discovery_passes}\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# # Run discovery across all grids\n",
    "# discovered_listings, engine = discover_all_grids(gird_coords_df, region_name, discovery_config)\n",
    "\n",
    "# print(f\"\\n‚úÖ Discovery complete!\")\n",
    "# print(f\"üìä Total unique listings: {len(discovered_listings)}\")\n",
    "# print(f\"üìÅ Saved to: Data/{region_name}/discovered_listings.json\")\n",
    "# print(f\"üìà Stats saved to: {discovery_config.stats_file}\")\n",
    "\n",
    "# # Convert discoveries to format compatible with enrichment pipeline\n",
    "# all_results = [listing.raw_data for listing in discovered_listings.values()]\n",
    "# print(f\"\\n‚úì Ready for enrichment pipeline with {len(all_results)} listings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ebc05d",
   "metadata": {},
   "source": [
    "# Step 2: Load Segmented Data for Enrichment\n",
    "\n",
    "**Flexible Grid Selection:**  \n",
    "- Specify which grids to process from the segmented data  \n",
    "- Leave `grids_to_process = None` to process **all available grids**  \n",
    "- Or set `grids_to_process = [1, 10, 15]` to process **only specific grids**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04c4179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start_index = grid_start_index\n",
    "# end_index = grid_end_index\n",
    "\n",
    "start_index = 1\n",
    "end_index = 110\n",
    "\n",
    "\n",
    "grid_index_array = np.arange(start_index, end_index+1)\n",
    "grid_index_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d279d16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Found 110 segmented data files in Data/Oakland/Segmented-Data\n",
      "  ‚úì Loaded grid 100: 2 listings\n",
      "  ‚úì Loaded grid 101: 1 listings\n",
      "  ‚úì Loaded grid 102: 0 listings\n",
      "  ‚úì Loaded grid 103: 0 listings\n",
      "  ‚úì Loaded grid 104: 0 listings\n",
      "  ‚úì Loaded grid 105: 0 listings\n",
      "  ‚úì Loaded grid 106: 0 listings\n",
      "  ‚úì Loaded grid 107: 0 listings\n",
      "  ‚úì Loaded grid 108: 11 listings\n",
      "  ‚úì Loaded grid 109: 11 listings\n",
      "  ‚úì Loaded grid 10: 10 listings\n",
      "  ‚úì Loaded grid 110: 13 listings\n",
      "  ‚úì Loaded grid 11: 2 listings\n",
      "  ‚úì Loaded grid 12: 185 listings\n",
      "  ‚úì Loaded grid 13: 171 listings\n",
      "  ‚úì Loaded grid 14: 46 listings\n",
      "  ‚úì Loaded grid 15: 27 listings\n",
      "  ‚úì Loaded grid 16: 3 listings\n",
      "  ‚úì Loaded grid 17: 0 listings\n",
      "  ‚úì Loaded grid 18: 2 listings\n",
      "  ‚úì Loaded grid 19: 1 listings\n",
      "  ‚úì Loaded grid 1: 44 listings\n",
      "  ‚úì Loaded grid 20: 8 listings\n",
      "  ‚úì Loaded grid 21: 2 listings\n",
      "  ‚úì Loaded grid 22: 147 listings\n",
      "  ‚úì Loaded grid 23: 177 listings\n",
      "  ‚úì Loaded grid 24: 84 listings\n",
      "  ‚úì Loaded grid 25: 28 listings\n",
      "  ‚úì Loaded grid 26: 0 listings\n",
      "  ‚úì Loaded grid 27: 4 listings\n",
      "  ‚úì Loaded grid 28: 0 listings\n",
      "  ‚úì Loaded grid 29: 0 listings\n",
      "  ‚úì Loaded grid 2: 161 listings\n",
      "  ‚úì Loaded grid 30: 2 listings\n",
      "  ‚úì Loaded grid 31: 1 listings\n",
      "  ‚úì Loaded grid 32: 31 listings\n",
      "  ‚úì Loaded grid 33: 61 listings\n",
      "  ‚úì Loaded grid 34: 88 listings\n",
      "  ‚úì Loaded grid 35: 85 listings\n",
      "  ‚úì Loaded grid 36: 15 listings\n",
      "  ‚úì Loaded grid 37: 0 listings\n",
      "  ‚úì Loaded grid 38: 0 listings\n",
      "  ‚úì Loaded grid 39: 0 listings\n",
      "  ‚úì Loaded grid 3: 141 listings\n",
      "  ‚úì Loaded grid 40: 0 listings\n",
      "  ‚úì Loaded grid 41: 0 listings\n",
      "  ‚úì Loaded grid 42: 15 listings\n",
      "  ‚úì Loaded grid 43: 92 listings\n",
      "  ‚úì Loaded grid 44: 21 listings\n",
      "  ‚úì Loaded grid 45: 33 listings\n",
      "  ‚úì Loaded grid 46: 48 listings\n",
      "  ‚úì Loaded grid 47: 7 listings\n",
      "  ‚úì Loaded grid 48: 0 listings\n",
      "  ‚úì Loaded grid 49: 0 listings\n",
      "  ‚úì Loaded grid 4: 7 listings\n",
      "  ‚úì Loaded grid 50: 0 listings\n",
      "  ‚úì Loaded grid 51: 0 listings\n",
      "  ‚úì Loaded grid 52: 0 listings\n",
      "  ‚úì Loaded grid 53: 4 listings\n",
      "  ‚úì Loaded grid 54: 3 listings\n",
      "  ‚úì Loaded grid 55: 16 listings\n",
      "  ‚úì Loaded grid 56: 24 listings\n",
      "  ‚úì Loaded grid 57: 3 listings\n",
      "  ‚úì Loaded grid 58: 1 listings\n",
      "  ‚úì Loaded grid 59: 5 listings\n",
      "  ‚úì Loaded grid 5: 4 listings\n",
      "  ‚úì Loaded grid 60: 3 listings\n",
      "  ‚úì Loaded grid 61: 0 listings\n",
      "  ‚úì Loaded grid 62: 0 listings\n",
      "  ‚úì Loaded grid 63: 0 listings\n",
      "  ‚úì Loaded grid 64: 0 listings\n",
      "  ‚úì Loaded grid 65: 9 listings\n",
      "  ‚úì Loaded grid 66: 18 listings\n",
      "  ‚úì Loaded grid 67: 39 listings\n",
      "  ‚úì Loaded grid 68: 38 listings\n",
      "  ‚úì Loaded grid 69: 15 listings\n",
      "  ‚úì Loaded grid 6: 4 listings\n",
      "  ‚úì Loaded grid 70: 1 listings\n",
      "  ‚úì Loaded grid 71: 0 listings\n",
      "  ‚úì Loaded grid 72: 0 listings\n",
      "  ‚úì Loaded grid 73: 0 listings\n",
      "  ‚úì Loaded grid 74: 0 listings\n",
      "  ‚úì Loaded grid 75: 0 listings\n",
      "  ‚úì Loaded grid 76: 2 listings\n",
      "  ‚úì Loaded grid 77: 28 listings\n",
      "  ‚úì Loaded grid 78: 42 listings\n",
      "  ‚úì Loaded grid 79: 26 listings\n",
      "  ‚úì Loaded grid 7: 4 listings\n",
      "  ‚úì Loaded grid 80: 1 listings\n",
      "  ‚úì Loaded grid 81: 0 listings\n",
      "  ‚úì Loaded grid 82: 0 listings\n",
      "  ‚úì Loaded grid 83: 0 listings\n",
      "  ‚úì Loaded grid 84: 0 listings\n",
      "  ‚úì Loaded grid 85: 0 listings\n",
      "  ‚úì Loaded grid 86: 0 listings\n",
      "  ‚úì Loaded grid 87: 15 listings\n",
      "  ‚úì Loaded grid 88: 26 listings\n",
      "  ‚úì Loaded grid 89: 10 listings\n",
      "  ‚úì Loaded grid 8: 7 listings\n",
      "  ‚úì Loaded grid 90: 3 listings\n",
      "  ‚úì Loaded grid 91: 0 listings\n",
      "  ‚úì Loaded grid 92: 0 listings\n",
      "  ‚úì Loaded grid 93: 0 listings\n",
      "  ‚úì Loaded grid 94: 0 listings\n",
      "  ‚úì Loaded grid 95: 0 listings\n",
      "  ‚úì Loaded grid 96: 0 listings\n",
      "  ‚úì Loaded grid 97: 3 listings\n",
      "  ‚úì Loaded grid 98: 12 listings\n",
      "  ‚úì Loaded grid 99: 9 listings\n",
      "  ‚úì Loaded grid 9: 7 listings\n",
      "\n",
      "======================================================================\n",
      "SEGMENTED DATA LOADED\n",
      "======================================================================\n",
      "Selected grids: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110]\n",
      "Actually processed: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110]\n",
      "Total listings loaded: 2169\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LOAD SEGMENTED DATA FOR ENRICHMENT\n",
    "# ============================================================================\n",
    "\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# CONFIGURE WHICH GRIDS TO PROCESS\n",
    "# Option 1: Process ALL grids (set to None)\n",
    "# Option 2: Process specific grids (e.g., [1, 10, 15])\n",
    "grids_to_process = grid_index_array  # Change this to [1, 10] to process only grids 1 and 10\n",
    "\n",
    "# Find all segmented listing files\n",
    "segmented_data_dir = Path(f\"Data/{region_name}/Segmented-Data\")\n",
    "listing_files = sorted(segmented_data_dir.glob(\"discovered_listings_grid_*.json\"))\n",
    "\n",
    "print(f\"üìÇ Found {len(listing_files)} segmented data files in {segmented_data_dir}\")\n",
    "\n",
    "# Load listings from selected grids\n",
    "all_results = []\n",
    "processed_grids = []\n",
    "\n",
    "for file_path in listing_files:\n",
    "    # Extract grid number from filename (e.g., \"discovered_listings_grid_11_20251221_040349.json\" -> 11)\n",
    "\n",
    "    filename = file_path.stem\n",
    "    try:\n",
    "        grid_num = int(filename.split('_')[3])  # Extract grid number\n",
    "    except (IndexError, ValueError):\n",
    "        print(f\"‚ö†Ô∏è Skipping file with unexpected name format: {file_path.name}\")\n",
    "        continue\n",
    "    \n",
    "    # Check if this grid should be processed\n",
    "    if grids_to_process is not None and grid_num not in grids_to_process:\n",
    "        continue  # Skip this grid\n",
    "    \n",
    "    # Load the JSON file\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            listings = data.get('listings', {})\n",
    "            \n",
    "            # Convert to list format compatible with enrichment code\n",
    "            for listing_id, listing_data in listings.items():\n",
    "                all_results.append(listing_data)\n",
    "            \n",
    "            processed_grids.append(grid_num)\n",
    "            print(f\"  ‚úì Loaded grid {grid_num}: {len(listings)} listings\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Error loading {file_path.name}: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SEGMENTED DATA LOADED\")\n",
    "print(\"=\" * 70)\n",
    "if grids_to_process is None:\n",
    "    print(f\"Selected grids: ALL ({len(processed_grids)} grids)\")\n",
    "else:\n",
    "    print(f\"Selected grids: {sorted(grids_to_process)}\")\n",
    "print(f\"Actually processed: {sorted(processed_grids)}\")\n",
    "print(f\"Total listings loaded: {len(all_results)}\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba4de3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2169"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_room_ids = []\n",
    "\n",
    "for res in all_results:\n",
    "    uni_room_ids.append(str(res['room_id']))\n",
    "\n",
    "uni_room_ids = list(set(uni_room_ids))\n",
    "\n",
    "len(uni_room_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c3d6ea",
   "metadata": {},
   "source": [
    "# 75, 55 Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PHASE 2: CHUNKED ENRICHMENT - Copy these cells to your notebook\n",
    "# ============================================================================\n",
    "\n",
    "# CELL 1: Configuration and Helper Functions\n",
    "# ============================================================================\n",
    "# Copy this entire cell to replace your current enrichment cell\n",
    "# ============================================================================\n",
    "\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "CHUNK_SIZE = 50  # Process 50 listings at a time\n",
    "OUTPUT_DIR = f\"Data/{region_name}/Enrichment_Chunks\"\n",
    "PROGRESS_FILE = f\"{OUTPUT_DIR}/progress.json\"\n",
    "FINAL_OUTPUT = f\"Data/{region_name}/summary_all_enriched.xlsx\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# üîß CONFIGURE PROCESSING RANGE HERE\n",
    "# Set to None to process all, or specify start/end indices\n",
    "START_INDEX = None  # Example: 0, 1000, 2000, etc.\n",
    "END_INDEX = None    # Example: 1000, 2000, 6000, etc.\n",
    "\n",
    "\n",
    "# Set today's date for calculations\n",
    "today = date.today()\n",
    "COMPLETE_MONTHS_THIS_YEAR = set([m for m in range(1, today.month+1)])\n",
    "COMPLETE_MONTHS_LAST_YEAR = set([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "\n",
    "print(\"üî¨ Starting CHUNKED enrichment phase...\")\n",
    "print(f\"üìÅ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"üì¶ Chunk size: {CHUNK_SIZE} listings per file\")\n",
    "print(f\"üìä Total discovered listings: {len(all_results)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def load_progress():\n",
    "    \"\"\"Load existing progress from disk\"\"\"\n",
    "    if os.path.exists(PROGRESS_FILE):\n",
    "        try:\n",
    "            with open(PROGRESS_FILE, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except:\n",
    "            return {\"completed_chunks\": [], \"last_updated\": None}\n",
    "    return {\"completed_chunks\": [], \"last_updated\": None}\n",
    "\n",
    "def save_progress(completed_chunks):\n",
    "    \"\"\"Save progress to disk\"\"\"\n",
    "    progress_data = {\n",
    "        \"completed_chunks\": completed_chunks,\n",
    "        \"last_updated\": datetime.now().isoformat(),\n",
    "        \"total_listings\": len(all_results),\n",
    "        \"chunk_size\": CHUNK_SIZE\n",
    "    }\n",
    "    with open(PROGRESS_FILE, 'w') as f:\n",
    "        json.dump(progress_data, f, indent=2)\n",
    "\n",
    "def save_chunk(chunk_id, chunk_start, chunk_end, chunk_data):\n",
    "    \"\"\"Save a chunk of enriched listings to disk\"\"\"\n",
    "    filename = f\"enrichment_chunk_{chunk_start:04d}_{chunk_end:04d}.json\"\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    \n",
    "    chunk_output = {\n",
    "        \"metadata\": {\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"start_index\": chunk_start,\n",
    "            \"end_index\": chunk_end,\n",
    "            \"total_listings\": len(chunk_data),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        },\n",
    "        \"listings\": chunk_data\n",
    "    }\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(chunk_output, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"  üíæ Saved chunk {chunk_id}: {filename} ({len(chunk_data)} listings)\")\n",
    "    return filepath\n",
    "\n",
    "def chunk_exists(chunk_start, chunk_end):\n",
    "    \"\"\"Check if a chunk file already exists\"\"\"\n",
    "    filename = f\"enrichment_chunk_{chunk_start:04d}_{chunk_end:04d}.json\"\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    return os.path.exists(filepath)\n",
    "\n",
    "# ============================================================================\n",
    "# DETERMINE PROCESSING RANGE\n",
    "# ============================================================================\n",
    "start_idx = START_INDEX if START_INDEX is not None else 0\n",
    "end_idx = END_INDEX if END_INDEX is not None else len(all_results)\n",
    "total_to_process = end_idx - start_idx\n",
    "\n",
    "print(f\"üéØ Processing range: {start_idx} to {end_idx} ({total_to_process} listings)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate chunks\n",
    "total_chunks = (total_to_process + CHUNK_SIZE - 1) // CHUNK_SIZE\n",
    "\n",
    "# Load existing progress\n",
    "progress = load_progress()\n",
    "completed_chunks = set(progress.get(\"completed_chunks\", []))\n",
    "if completed_chunks:\n",
    "    print(f\"üìã Found {len(completed_chunks)} already completed chunks (will skip)\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 2: Main Processing Loop\n",
    "# ============================================================================\n",
    "# Copy this as a SEPARATE cell\n",
    "# ============================================================================\n",
    "\n",
    "# Statistics\n",
    "total_passed_75 = 0\n",
    "total_failed_75 = 0\n",
    "total_errors = 0\n",
    "chunks_processed = 0\n",
    "\n",
    "# Error listings\n",
    "roomIDs_with_errors = []\n",
    "\n",
    "\n",
    "# Process each chunk\n",
    "for chunk_id in range(total_chunks):\n",
    "    chunk_start = start_idx + (chunk_id * CHUNK_SIZE)\n",
    "    chunk_end = min(chunk_start + CHUNK_SIZE, end_idx)\n",
    "    \n",
    "    # Skip if chunk already exists\n",
    "    if chunk_exists(chunk_start, chunk_end - 1):\n",
    "        print(f\"‚è≠Ô∏è  Chunk {chunk_id + 1}/{total_chunks}: {chunk_start}-{chunk_end-1} already processed, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nüîÑ Processing Chunk {chunk_id + 1}/{total_chunks}: Listings {chunk_start}-{chunk_end-1}\")\n",
    "    \n",
    "    chunk_data = []\n",
    "    chunk_passed_75 = 0\n",
    "    chunk_failed_75 = 0\n",
    "    chunk_errors = []\n",
    "    \n",
    "    # Process listings in this chunk\n",
    "    for idx in range(chunk_start, chunk_end):\n",
    "        result = all_results[idx]\n",
    "        \n",
    "        try:\n",
    "            room_id = result['room_id']\n",
    "\n",
    "            room_url = f\"https://www.airbnb.com.sg/rooms/{room_id}\"\n",
    "            \n",
    "            # Progress indicator\n",
    "            if (idx - chunk_start + 1) % 10 == 0:\n",
    "                print(f\"  {idx - chunk_start + 1}/{chunk_end - chunk_start} in this chunk...\")\n",
    "                # Rate limiting\n",
    "                time.sleep(random.uniform(2, 5))\n",
    "            \n",
    "            # Get listing details\n",
    "            listing_details = pyairbnb.get_details(room_url=room_url, currency=\"USD\", language=\"en\")\n",
    "            \n",
    "            # Extract all data\n",
    "            accuracy_rating = listing_details['rating']['accuracy']\n",
    "            checking_rating = listing_details['rating']['checking']\n",
    "            cleanliness_rating = listing_details['rating']['cleanliness']\n",
    "            communication_rating = listing_details['rating']['communication']\n",
    "            location_rating = listing_details['rating']['location']\n",
    "            value_rating = listing_details['rating']['value']\n",
    "            overall_rating = listing_details['rating']['guest_satisfaction']\n",
    "\n",
    "            review_count = listing_details['rating']['review_count']\n",
    "            latitude = listing_details['coordinates']['latitude']\n",
    "            longitude = listing_details['coordinates']['longitude']\n",
    "            \n",
    "            # Superhost\n",
    "            if 'is_superhost' in listing_details.keys():\n",
    "                is_superhost = listing_details['is_superhost']\n",
    "            elif 'is_super_host' in listing_details.keys():\n",
    "                is_superhost = listing_details['is_super_host']\n",
    "            else:\n",
    "                is_superhost = \"ERROR\"\n",
    "            \n",
    "            configuration = listing_details['sub_description']['items']\n",
    "            guest_count, bedroom_count, bed_count, bath_count = get_configuration(configuration)\n",
    "            \n",
    "            amenities = listing_details['amenities']\n",
    "            co_hosts = listing_details['co_hosts']\n",
    "            highlights = listing_details['highlights']\n",
    "            is_guest_favorite = listing_details['is_guest_favorite']\n",
    "            title = listing_details['title']\n",
    "            grid_index = result.get('grid_index', None)\n",
    "            \n",
    "            available_dates_by_year_and_month = get_available_dates_by_year_and_month(listing_details)\n",
    "\n",
    "            days_booked_next30days = 30 - get_available_dates_75Rule(available_dates_by_year_and_month)\n",
    "            days_booked_nextnext30days = 30 - get_available_dates_55Rule(available_dates_by_year_and_month)\n",
    "\n",
    "            rule75_met = days_booked_next30days >= 22 \n",
    "            rule55_met = days_booked_nextnext30days >= 16\n",
    "\n",
    "            if rule75_met:\n",
    "                chunk_passed_75 += 1\n",
    "            else:\n",
    "                chunk_failed_75 += 1\n",
    "            \n",
    "            # Calendar analysis\n",
    "            # calendar_info = listing_details['calendar']\n",
    "            # curr_month_available_dates = get_available_dates(calendar_info[0])\n",
    "            # next_month_available_dates = get_available_dates(calendar_info[1])\n",
    "            # next_two_months_available_dates = get_available_dates(calendar_info[2])\n",
    "            \n",
    "            # rule75_met, days_booked_next30days = check_75_rule(\n",
    "            #     curr_month_available_dates=curr_month_available_dates,\n",
    "            #     next_month_available_dates=next_month_available_dates,\n",
    "            #     leniency=1\n",
    "            # )\n",
    "            \n",
    "            # rule55_met, days_booked_nextnext30days = check_55_rule(\n",
    "            #     next_month_available_dates=next_month_available_dates,\n",
    "            #     next_two_months_available_dates=next_two_months_available_dates,\n",
    "            #     leniency=2\n",
    "            # )\n",
    "            \n",
    "            # Reviews analysis\n",
    "            review_months = analyze_reviews(room_id)\n",
    "            review_months_this_year = review_months.get(today.year, set())\n",
    "            review_months_last_year = review_months.get(today.year - 1, set())\n",
    "            \n",
    "            warning_level, warning_type, warning_message = check_reviews_count(\n",
    "                review_months_this_year=review_months_this_year,\n",
    "                review_months_last_year=review_months_last_year,\n",
    "                leniency=3\n",
    "            )\n",
    "            \n",
    "            missing_review_months_this_year = list(COMPLETE_MONTHS_THIS_YEAR - review_months_this_year)\n",
    "            missing_review_months_last_year = list(COMPLETE_MONTHS_LAST_YEAR - review_months_last_year)\n",
    "\n",
    "            ##### New Approach\n",
    "            review_count_by_year_and_month = get_review_count_by_year_and_month(listing_details['reviews'])\n",
    "\n",
    "            # Store as dictionary (not DataFrame row - much faster!)\n",
    "            listing_record = {\n",
    "                'Room_id': room_id,\n",
    "                'Listing_url': room_url,\n",
    "                'Next_30_days_booked_days': days_booked_next30days,\n",
    "                'Next_30_to_60_days_booked_days': days_booked_nextnext30days,\n",
    "                '75_rule_met': rule75_met,\n",
    "                '55_rule_met': rule55_met,\n",
    "                'Available_dates_by_year_and_month': available_dates_by_year_and_month,\n",
    "                'Review_count_by_year_and_month': review_count_by_year_and_month,\n",
    "                'Warning_level': warning_level,\n",
    "                'Warning_type': warning_type,\n",
    "                'Warning_message': warning_message,\n",
    "\n",
    "                'Rating': overall_rating,\n",
    "                'Accuracy_rating': accuracy_rating,\n",
    "                'Checking_rating': checking_rating,\n",
    "                'Cleanliness_rating': cleanliness_rating,\n",
    "                'Communication_rating': communication_rating,\n",
    "                'Location_rating': location_rating,\n",
    "                'Value_rating': value_rating,\n",
    "                \n",
    "                'Review_count': review_count,\n",
    "                'Review_months_this_year': list(review_months_this_year),\n",
    "                'Review_months_last_year': list(review_months_last_year),\n",
    "                'Missing_review_months_this_year': missing_review_months_this_year,\n",
    "                'Missing_review_months_last_year': missing_review_months_last_year,\n",
    "                'Total_missing_review_months_this_year': len(missing_review_months_this_year),\n",
    "                'Total_missing_review_months_last_year': len(missing_review_months_last_year),\n",
    "                'Is_superhost': is_superhost,\n",
    "                'Guest_count': guest_count,\n",
    "                'Bedroom_count': bedroom_count,\n",
    "                'Bed_count': bed_count,\n",
    "                'Bath_count': bath_count,\n",
    "                'Amenities': amenities,\n",
    "                'Co_hosts': co_hosts,\n",
    "                'Highlights': highlights,\n",
    "                'Is_guest_favorite': is_guest_favorite,\n",
    "                'Title': title,\n",
    "                'Latitude': latitude,\n",
    "                'Longitude': longitude,\n",
    "                'Grid_index': grid_index,\n",
    "            }\n",
    "            \n",
    "            chunk_data.append(listing_record)\n",
    "\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error processing room_id {result.get('room_id', 'unknown')}: {str(e)}\"\n",
    "            print(f\"  ‚ö†Ô∏è {error_msg}\")\n",
    "            roomIDs_with_errors.append(result.get('room_id'))\n",
    "            chunk_errors.append({\n",
    "                \"room_id\": result.get('room_id'),\n",
    "                \"error\": str(e),\n",
    "                \"index\": idx\n",
    "            })\n",
    "    \n",
    "    # Save this chunk\n",
    "    save_chunk(chunk_id, chunk_start, chunk_end - 1, chunk_data)\n",
    "    \n",
    "    # Update progress\n",
    "    completed_chunks.add(chunk_id)\n",
    "    save_progress(list(completed_chunks))\n",
    "    \n",
    "    # Update statistics\n",
    "    total_passed_75 += chunk_passed_75\n",
    "    total_failed_75 += chunk_failed_75\n",
    "    total_errors += len(chunk_errors)\n",
    "    chunks_processed += 1\n",
    "    \n",
    "    print(f\"  ‚úÖ Chunk complete: {chunk_passed_75} passed 75%, {chunk_failed_75} failed, {len(chunk_errors)} errors\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ CHUNKED ENRICHMENT COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total chunks processed: {chunks_processed}/{total_chunks}\")\n",
    "print(f\"Total passed 75% rule: {total_passed_75}\")\n",
    "print(f\"Total failed 75% rule: {total_failed_75}\")\n",
    "print(f\"Total errors: {total_errors}\")\n",
    "print(f\"üìÅ Chunk files saved in: {OUTPUT_DIR}\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüí° Next step: Run the consolidation cell below to create final Excel file\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 3: Consolidation Function\n",
    "# ============================================================================\n",
    "# Copy this as a SEPARATE cell\n",
    "# Run this AFTER all chunks are processed to create the final Excel file\n",
    "# ============================================================================\n",
    "\n",
    "def consolidate_chunks_to_excel():\n",
    "    \"\"\"Merge all chunk files into one final Excel file\"\"\"\n",
    "    print(\"üîÑ Consolidating all chunks into final Excel...\")\n",
    "    \n",
    "    all_data = []\n",
    "    chunk_files = sorted([f for f in os.listdir(OUTPUT_DIR) if f.startswith('enrichment_chunk_') and f.endswith('.json')])\n",
    "    \n",
    "    print(f\"üìÅ Found {len(chunk_files)} chunk files\")\n",
    "    \n",
    "    for chunk_file in chunk_files:\n",
    "        filepath = os.path.join(OUTPUT_DIR, chunk_file)\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                chunk_data = json.load(f)\n",
    "                all_data.extend(chunk_data['listings'])\n",
    "            print(f\"  ‚úÖ Loaded {chunk_file}: {len(chunk_data['listings'])} listings\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error loading {chunk_file}: {e}\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    summary_df = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Save to Excel\n",
    "    summary_df.to_excel(FINAL_OUTPUT, index=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Consolidation complete!\")\n",
    "    print(f\"üìä Total listings: {len(summary_df)}\")\n",
    "    print(f\"üìÅ Saved to: {FINAL_OUTPUT}\")\n",
    "    \n",
    "    return summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run consolidation\n",
    "summary_df = consolidate_chunks_to_excel()\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204b1e7f",
   "metadata": {},
   "source": [
    "##### \n",
    "\n",
    "https://www.airbnb.com/rooms/1506163384607639418?check_in=2026-01-02&check_out=2026-01-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349c26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26436d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_df = pd.concat([summary_df, missing_summary_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a9531",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_summary_path = f\"Output-Summary-Data/{region_name}_listings_results_grid_{1}_to_{120}.csv\"\n",
    "output_summary_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e08cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_csv(output_summary_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088c38fc",
   "metadata": {},
   "source": [
    "# Search Room IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_links = [\n",
    "    \"https://www.airbnb.co.uk/rooms/1506163384607639418?location=Napa%2C%20CA&search_mode=regular_search&adults=1&source_impression_id=p3_1765407790_P3-0aYGmiG-QRrvX&previous_page_section_name=1001&federated_search_id=1f38d13e-d757-483e-a64d-62a424e4b5f1&guests=1\",\n",
    "    \"https://www.airbnb.co.uk/rooms/1269151490151009015?location=Napa%2C%20CA&search_mode=regular_search&adults=1&source_impression_id=p3_1765408749_P3q2kzaN2fS-Xtfn&previous_page_section_name=1001&federated_search_id=c9fa4f15-85d3-491d-85e9-1c8e82ad7d51&guests=1\",\n",
    "    \"https://www.airbnb.co.uk/rooms/613718467814096374?location=Napa%2C%20CA&search_mode=regular_search&adults=1&source_impression_id=p3_1765409074_P3Ft3C2-JnHomL-q&previous_page_section_name=1001&federated_search_id=462ee2f7-00e0-4af9-825b-086bf9e349e5&guests=1\",\n",
    "    \"https://www.airbnb.co.uk/rooms/3208254?location=Napa%2C%20CA&search_mode=regular_search&adults=1&source_impression_id=p3_1765409076_P3xcYx0o1UWIeJld&previous_page_section_name=1001&federated_search_id=462ee2f7-00e0-4af9-825b-086bf9e349e5&guests=1&check_in=2026-01-05&check_out=2026-01-07\",\n",
    "    \"https://www.airbnb.co.uk/rooms/702505738423530993?location=Napa%2C%20CA&search_mode=regular_search&adults=1&source_impression_id=p3_1765409081_P31wzND1HZQx6--D&previous_page_section_name=1001&federated_search_id=462ee2f7-00e0-4af9-825b-086bf9e349e5&guests=1#availability-calendar\",\n",
    "    \"https://www.airbnb.co.uk/rooms/31618189?location=Napa%2C%20CA&search_mode=regular_search&adults=1&source_impression_id=p3_1765419141_P3A7FAnASZ9vnHOZ&previous_page_section_name=1001&federated_search_id=395191b1-28a2-4ca5-b874-fd9e5e9806ea&guests=1\",\n",
    "    \"https://www.airbnb.co.uk/rooms/32017392?location=Napa%2C%20CA&search_mode=regular_search&adults=1&source_impression_id=p3_1765419142_P3V78M9jeeZTCqzS&previous_page_section_name=1001&federated_search_id=395191b1-28a2-4ca5-b874-fd9e5e9806ea&guests=1&check_in=2025-12-13&check_out=2025-12-15\",\n",
    "    \"https://www.airbnb.co.uk/rooms/1014152739375310984?location=Napa%2C%20CA&search_mode=regular_search&adults=1&source_impression_id=p3_1765420517_P3vHJ6mN1WMqMLDO&previous_page_section_name=1001&federated_search_id=cd9b34b8-7553-47ef-87d4-15e375750603&guests=1\",\n",
    "    \"https://www.airbnb.co.uk/rooms/1413329775040945628?location=Napa%2C%20CA&search_mode=regular_search&adults=1&source_impression_id=p3_1765420850_P3mW5Q6SW84GvZio&previous_page_section_name=1001&federated_search_id=942c6549-8761-4ae3-b927-2c0e33ef169f&guests=1&check_in=2026-01-07&check_out=2026-01-09\",\n",
    "    \"https://www.airbnb.co.uk/rooms/1279294796042952467?location=Napa%2C%20CA&search_mode=regular_search&adults=1&source_impression_id=p3_1765420908_P3S730efQJLvmgwB&previous_page_section_name=1001&federated_search_id=948a60e6-f98a-4b99-8568-c7e8a363f6d9&guests=1#availability-calendar\",\n",
    "    \"https://www.airbnb.co.uk/rooms/34838894?location=Napa%2C%20CA&search_mode=regular_search&adults=1&source_impression_id=p3_1765422549_P3R6UyXWwQAYWEy8&previous_page_section_name=1001&federated_search_id=426f9609-5f1c-461d-91f2-0672fd233efa&guests=1&check_in=2026-01-19&check_out=2026-01-21\",\n",
    "    \"https://www.airbnb.co.uk/rooms/1515200652264910676?location=Napa%2C%20CA&search_mode=regular_search&adults=1&source_impression_id=p3_1765423726_P3aIgNz8v7Du9YKB&previous_page_section_name=1001&federated_search_id=01f47499-8e09-445c-b131-b6f76de501b1&guests=1\",\n",
    "    \"https://www.airbnb.co.uk/rooms/1364847844572148487?location=Napa%2C%20CA&search_mode=regular_search&adults=1&source_impression_id=p3_1765409068_P3ml-kaNRiXKslyO&previous_page_section_name=1001&federated_search_id=15f4969e-18be-4545-99a7-94a76e9866c1&guests=1&check_in=2026-01-02&check_out=2026-01-04\",\n",
    "    \"https://www.airbnb.co.uk/rooms/1506163384607639418?location=Napa%2C%20CA&search_mode=regular_search&adults=1&source_impression_id=p3_1765407790_P3-0aYGmiG-QRrvX&previous_page_section_name=1001&federated_search_id=1f38d13e-d757-483e-a64d-62a424e4b5f1&guests=1\",\n",
    "    \"https://www.airbnb.co.uk/rooms/1515200652264910676?location=Napa%2C%20CA&search_mode=regular_search&adults=1&source_impression_id=p3_1765423726_P3aIgNz8v7Du9YKB&previous_page_section_name=1001&federated_search_id=01f47499-8e09-445c-b131-b6f76de501b1&guests=1\",\n",
    "]\n",
    "\n",
    "test_room_ID_list = []\n",
    "\n",
    "for link in test_links:\n",
    "    link = link.split(\"?\")[0]\n",
    "    link = link.split(\"rooms/\")[1]\n",
    "    test_room_ID_list.append(int(link))\n",
    "\n",
    "for room_id in test_room_ID_list:\n",
    "    if room_id not in summary_df['Room_id'].values:\n",
    "        print(room_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc73a1",
   "metadata": {},
   "source": [
    "# Missing and Debug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0976ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_room_ID_list = [\n",
    "    935168255357797927,\n",
    "    1185926597599979261,\n",
    "    25254687,\n",
    "]\n",
    "\n",
    "\n",
    "debug_mode = False\n",
    "\n",
    "\n",
    "# Set today's date for calculations\n",
    "today = date.today()\n",
    "COMPLETE_MONTHS_THIS_YEAR = set([m for m in range(1, today.month+1)])\n",
    "COMPLETE_MONTHS_LAST_YEAR = set([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "\n",
    "print(\"üî¨ Starting enrichment phase...\")\n",
    "print(f\"Total discovered listings to process: {len(all_results)}\")\n",
    "print(f\"Strategy: Only enrich listings that pass 75% rule\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Initialize summary DataFrame\n",
    "missing_summary_df = pd.DataFrame(columns=[\n",
    "    'Room_id', 'Listing_url', \n",
    "    'Next_30_days_booked_days', 'Next_30_to_60_days_booked_days',\n",
    "    '75_rule_met', '55_rule_met',\n",
    "    'Warning_level', 'Warning_type', 'Warning_message',\n",
    "    'Rating', 'Review_count',\n",
    "    'Review_months_this_year', 'Review_months_last_year',\n",
    "    'Missing_review_months_this_year', 'Missing_review_months_last_year',\n",
    "    'Total_missing_review_months_this_year', 'Total_missing_review_months_last_year',\n",
    "    'Latitude', 'Longitude', 'Grid_index'\n",
    "])\n",
    "\n",
    "# Process each discovered listing\n",
    "listings_passed_75_rule = 0\n",
    "listings_failed_75_rule = 0\n",
    "enrichment_errors = []\n",
    "\n",
    "\n",
    "for idx, room_id in enumerate(test_room_ID_list):\n",
    "    try:\n",
    "        # room_id = result['room_id']\n",
    "        room_url = f\"https://www.airbnb.com.sg/rooms/{room_id}\"\n",
    "\n",
    "        if debug_mode:\n",
    "            print(f\"room_url: {room_url}\")\n",
    "        \n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"  Processing {idx + 1}/{len(all_results)}... (75% pass: {listings_passed_75_rule}, skip: {listings_failed_75_rule})\")\n",
    "            # Add random delay every 10 listings to avoid rate limiting\n",
    "            delay = random.uniform(2, 5)  # Random delay between 2-5 seconds\n",
    "            # print(f\"  ‚è∏Ô∏è  Pausing for {delay:.1f}s to avoid rate limits...\")\n",
    "            time.sleep(delay) \n",
    "        \n",
    "        listing_details = pyairbnb.get_details(room_url=room_url, currency=\"USD\", language=\"en\")\n",
    "        \n",
    "        print(type(listing_details))\n",
    "        print(\"listing_details: \", listing_details)\n",
    "\n",
    "        if listing_details is None: \n",
    "            print(f\"room_url: {room_url} is not found\")\n",
    "            break\n",
    "\n",
    "        if debug_mode:\n",
    "            print(\"CP - 0\")\n",
    "            print(listing_details.keys())\n",
    "        \n",
    "        # Category Ratings\n",
    "        accuracy_rating = listing_details['rating']['accuracy']\n",
    "        checking_rating = listing_details['rating']['checking']\n",
    "        cleanliness_rating = listing_details['rating']['cleanliness']\n",
    "        communication_rating = listing_details['rating']['communication']\n",
    "        location_rating = listing_details['rating']['location']\n",
    "        value_rating = listing_details['rating']['value']\n",
    "        overall_rating = listing_details['rating']['guest_satisfaction']\n",
    "\n",
    "        # Review Count\n",
    "        review_count = listing_details['rating']['review_count']\n",
    "        latitude = listing_details['coordinates']['latitude']\n",
    "        longitude = listing_details['coordinates']['longitude']\n",
    "\n",
    "        # Coordinates\n",
    "        latitude = listing_details['coordinates']['latitude']\n",
    "        longitude = listing_details['coordinates']['longitude']\n",
    "\n",
    "        # Superhost\n",
    "        if 'is_superhost' in listing_details.keys():\n",
    "            is_superhost = listing_details['is_superhost']\n",
    "        elif 'is_super_host' in listing_details.keys():\n",
    "            is_superhost = listing_details['is_super_host']\n",
    "        else:\n",
    "            is_superhost = None\n",
    "\n",
    "        if debug_mode:\n",
    "            print(\"CP - 5\")\n",
    "            print(\"sub_description : \", listing_details['sub_description'])\n",
    "\n",
    "        # Configuration (guest, bedroom, bed, bath counts)\n",
    "        configuration = listing_details['sub_description']['items']\n",
    "\n",
    "        if debug_mode:\n",
    "            print(\"CP - 6\")\n",
    "        \n",
    "        guest_count, bedroom_count, bed_count, bath_count = get_configuration(configuration)\n",
    "\n",
    "        if debug_mode:\n",
    "            print(\"configuration: \", configuration)\n",
    "            print(\"guest_count, bedroom_count, bed_count, bath_count: \", guest_count, bedroom_count, bed_count, bath_count)\n",
    "            print(\"CP - 7\")\n",
    "\n",
    "        # Amenities\n",
    "        amenities = listing_details['amenities']\n",
    "\n",
    "        if debug_mode:\n",
    "            print(\"CP - 8\")\n",
    "\n",
    "        # Cohost\n",
    "        co_hosts = listing_details['co_hosts']\n",
    "\n",
    "        if debug_mode:\n",
    "            print(\"CP - 9\")\n",
    "\n",
    "        # Hightlights\n",
    "        highlights = listing_details['highlights']\n",
    "\n",
    "        if debug_mode:\n",
    "            print(\"CP - 10\")\n",
    "\n",
    "        # Is Guest Favorite\n",
    "        is_guest_favorite = listing_details['is_guest_favorite']\n",
    "\n",
    "        if debug_mode:\n",
    "            print(\"CP - 11\")\n",
    "\n",
    "        # Title\n",
    "        title = listing_details['title']\n",
    "\n",
    "        if debug_mode:\n",
    "            print(\"CP - 12\")\n",
    "\n",
    "        # Gird Index\n",
    "        # grid_index = result.get('grid_index', None)\n",
    "\n",
    "        available_dates_by_year_and_month = get_available_dates_by_year_and_month(listing_details)\n",
    "\n",
    "        days_booked_next30days = 30 - get_available_dates_75Rule(available_dates_by_year_and_month)\n",
    "        days_booked_nextnext30days = 30 - get_available_dates_55Rule(available_dates_by_year_and_month)\n",
    "\n",
    "        rule75_met = days_booked_next30days >= 22 \n",
    "        rule55_met = days_booked_nextnext30days >= 16\n",
    "\n",
    "        if rule75_met:\n",
    "            chunk_passed_75 += 1\n",
    "        else:\n",
    "            chunk_failed_75 += 1\n",
    "\n",
    "\n",
    "        # Reviews analysis\n",
    "        review_months = analyze_reviews(room_id)\n",
    "        review_months_this_year = review_months.get(today.year, set())\n",
    "        review_months_last_year = review_months.get(today.year - 1, set())\n",
    "        \n",
    "        warning_level, warning_type, warning_message = check_reviews_count(\n",
    "            review_months_this_year=review_months_this_year,\n",
    "            review_months_last_year=review_months_last_year,\n",
    "            leniency=3\n",
    "        )\n",
    "        \n",
    "        missing_review_months_this_year = list(COMPLETE_MONTHS_THIS_YEAR - review_months_this_year)\n",
    "        missing_review_months_last_year = list(COMPLETE_MONTHS_LAST_YEAR - review_months_last_year)\n",
    "\n",
    "        ##### New Approach\n",
    "        review_count_by_year_and_month = get_review_count_by_year_and_month(listing_details['reviews'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # # Reviews Count by Year and Month\n",
    "        # review_count_by_year_and_month = get_review_count_by_year_and_month(listing_details['reviews'])\n",
    "\n",
    "        # if debug_mode:\n",
    "        #     print(\"CP - 12 - A\")\n",
    "\n",
    "        # if debug_mode:\n",
    "        #     print(\"review_count_by_year_and_month: \", review_count_by_year_and_month)\n",
    "\n",
    "        # # Available Dates by Year and Month FOR BACKUP\n",
    "        # available_dates_by_year_and_month = get_available_dates_by_year_and_month(listing_details)\n",
    "\n",
    "        # if debug_mode:\n",
    "        #     print(\"available_dates_by_year_and_month: \", available_dates_by_year_and_month)\n",
    "        \n",
    "        # # Get calendar data (3 months)\n",
    "        # if debug_mode:\n",
    "        #     print(\"CP - 13\")\n",
    "        #     print(\"listing_details 000: \", listing_details['calendar'])\n",
    "\n",
    "        # calendar_info = listing_details['calendar']\n",
    "\n",
    "        # if debug_mode:\n",
    "        #     print(\"calendar: \", calendar_info)\n",
    "\n",
    "        # current_month_calendar = calendar_info[0]\n",
    "        # next_month_calendar = calendar_info[1]\n",
    "        # next_two_months_calendar = calendar_info[2]\n",
    "\n",
    "        # if debug_mode:\n",
    "        #     print(\"CP - 14\")\n",
    "        \n",
    "        # curr_month_available_dates = get_available_dates(current_month_calendar)\n",
    "        # next_month_available_dates = get_available_dates(next_month_calendar)\n",
    "        # next_two_months_available_dates = get_available_dates(next_two_months_calendar)\n",
    "\n",
    "        # if debug_mode:\n",
    "        #     print(\"CP - 15\")\n",
    "        \n",
    "        # # Check 75% rule (next 30 days, leniency=2)\n",
    "        # rule75_met, days_booked_next30days = check_75_rule(\n",
    "        #     curr_month_available_dates=curr_month_available_dates,\n",
    "        #     next_month_available_dates=next_month_available_dates,\n",
    "        #     leniency=2\n",
    "        # )\n",
    "\n",
    "        # if debug_mode:\n",
    "        #     print(\"CP - 16\")\n",
    "        \n",
    "        # # ONLY PROCESS IF 75% RULE IS MET\n",
    "        # # if True:  # Get all info regardless of 75% rule\n",
    "\n",
    "        # if rule75_met:\n",
    "        #     listings_passed_75_rule += 1\n",
    "        # else: \n",
    "        #     listings_failed_75_rule += 1\n",
    "        \n",
    "        # # Check 55% rule (days 31-60, leniency=2)\n",
    "        # rule55_met, days_booked_nextnext30days = check_55_rule(\n",
    "        #     next_month_available_dates=next_month_available_dates,\n",
    "        #     next_two_months_available_dates=next_two_months_available_dates,\n",
    "        #     leniency=2\n",
    "        # )\n",
    "        \n",
    "        # # Get reviews data\n",
    "        # review_months = analyze_reviews(room_id)\n",
    "        \n",
    "        # if today.year in review_months:\n",
    "        #     review_months_this_year = review_months[today.year]\n",
    "        # else:\n",
    "        #     review_months_this_year = set()\n",
    "        \n",
    "        # if today.year - 1 in review_months:\n",
    "        #     review_months_last_year = review_months[today.year - 1]\n",
    "        # else:\n",
    "        #     review_months_last_year = set()\n",
    "        \n",
    "        # # Check review frequency (leniency=3)\n",
    "        # warning_level, warning_type, warning_message = check_reviews_count(\n",
    "        #     review_months_this_year=review_months_this_year,\n",
    "        #     review_months_last_year=review_months_last_year,\n",
    "        #     leniency=3\n",
    "        # )\n",
    "        \n",
    "        # missing_review_months_this_year = list(COMPLETE_MONTHS_THIS_YEAR - review_months_this_year)\n",
    "        # missing_review_months_last_year = list(COMPLETE_MONTHS_LAST_YEAR - review_months_last_year)\n",
    "        \n",
    "        # Add to summary DataFrame\n",
    "        new_row = pd.DataFrame([{\n",
    "            'Room_id': room_id,\n",
    "            'Listing_url': room_url,\n",
    "\n",
    "            'Next_30_days_booked_days': days_booked_next30days,\n",
    "            'Next_30_to_60_days_booked_days': days_booked_nextnext30days,\n",
    "            '75_rule_met': rule75_met,\n",
    "            '55_rule_met': rule55_met,\n",
    "\n",
    "            'Available_dates_by_year_and_month': available_dates_by_year_and_month,\n",
    "            'Review_count_by_year_and_month': review_count_by_year_and_month,\n",
    "\n",
    "            'Warning_level': warning_level,\n",
    "            'Warning_type': warning_type,\n",
    "            'Warning_message': warning_message,\n",
    "\n",
    "            'Rating': overall_rating,\n",
    "            'Accuracy_rating': accuracy_rating,\n",
    "            'Checking_rating': checking_rating,\n",
    "            'Cleanliness_rating': cleanliness_rating,\n",
    "            'Communication_rating': communication_rating,\n",
    "            'Location_rating': location_rating,\n",
    "            'Value_rating': value_rating,\n",
    "            'Overall_rating': overall_rating,\n",
    "\n",
    "            'Review_count': review_count,\n",
    "            'Review_months_this_year': list(review_months_this_year),\n",
    "            'Review_months_last_year': list(review_months_last_year),\n",
    "            'Missing_review_months_this_year': missing_review_months_this_year,\n",
    "            'Missing_review_months_last_year': missing_review_months_last_year,\n",
    "            'Total_missing_review_months_this_year': len(missing_review_months_this_year),\n",
    "            'Total_missing_review_months_last_year': len(missing_review_months_last_year),\n",
    "\n",
    "            'Is_superhost': is_superhost,\n",
    "            'Guest_count': guest_count,\n",
    "            'Bedroom_count': bedroom_count,\n",
    "            'Bed_count': bed_count,\n",
    "            'Bath_count': bath_count,\n",
    "\n",
    "            'Amenities': amenities,\n",
    "            'Co_hosts': co_hosts,\n",
    "            'Highlights': highlights,\n",
    "            'Is_guest_favorite': is_guest_favorite,\n",
    "            'Title': title,\n",
    "\n",
    "            'Latitude': latitude,\n",
    "            'Longitude': longitude,\n",
    "            'Grid_index': grid_index,\n",
    "        }])\n",
    "        \n",
    "        missing_summary_df = pd.concat([missing_summary_df, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error processing room_id {result.get('room_id', 'unknown')}: {str(e)}\"\n",
    "        print(f\"  ‚ö†Ô∏è {error_msg}\")\n",
    "        enrichment_errors.append(error_msg)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ ENRICHMENT COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total discovered listings: {len(all_results)}\")\n",
    "print(f\"Passed 75% rule (enriched): {listings_passed_75_rule}\")\n",
    "print(f\"Failed 75% rule (skipped): {listings_failed_75_rule}\")\n",
    "print(f\"Errors during enrichment: {len(enrichment_errors)}\")\n",
    "print(f\"Final qualified listings: {len(missing_summary_df)}\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f08c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_id = \"805725215071886985\"\n",
    "room_url = f\"https://www.airbnb.com.sg/rooms/{room_id}\"\n",
    "listing_details = pyairbnb.get_details(room_url=room_url, currency=\"USD\", language=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cb312",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in test_room_ID_list:\n",
    "    if id not in missing_summary_df['Room_id'].tolist():\n",
    "        print(f\"www.airbnb.com/rooms/{id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec46168",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_summary_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary_df = pd.concat([summary_df, missing_summary_df], axis=0)\n",
    "final_summary_df.reset_index(drop=True, inplace=True)\n",
    "print(final_summary_df.columns)\n",
    "final_summary_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce94052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2a3f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Recalculate 75% and 55% Rules from Available_dates_by_year_and_month\n",
    "# ============================================================================\n",
    "\n",
    "from datetime import date, timedelta\n",
    "import calendar\n",
    "\n",
    "# Get today's date\n",
    "today = date.today()\n",
    "\n",
    "\n",
    "\n",
    "# Calculate date ranges\n",
    "next_30_days_start = today\n",
    "next_30_days_end = today + timedelta(days=29)  # Days 0-29 (30 days total)\n",
    "\n",
    "next_31_to_60_start = today + timedelta(days=30)  # Day 30\n",
    "next_31_to_60_end = today + timedelta(days=59)    # Day 59 (30 days total)\n",
    "\n",
    "print(f\"üìÖ Calculating available days from stored calendar data...\")\n",
    "print(f\"Today: {today}\")\n",
    "print(f\"Next 30 days: {next_30_days_start} to {next_30_days_end}\")\n",
    "print(f\"Days 31-60: {next_31_to_60_start} to {next_31_to_60_end}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Apply the function to each row\n",
    "final_summary_df['Next_30_days_available_days_NEW'] = final_summary_df['Available_dates_by_year_and_month'].apply(\n",
    "    lambda x: count_available_days_in_range(x, next_30_days_start, next_30_days_end)\n",
    ")\n",
    "\n",
    "final_summary_df['Next_30_to_60_days_available_days_NEW'] = final_summary_df['Available_dates_by_year_and_month'].apply(\n",
    "    lambda x: count_available_days_in_range(x, next_31_to_60_start, next_31_to_60_end)\n",
    ")\n",
    "\n",
    "# Calculate booked days (30 - available = booked)\n",
    "final_summary_df['Next_30_days_booked_days_NEW'] = 30 - final_summary_df['Next_30_days_available_days_NEW']\n",
    "final_summary_df['Next_30_to_60_days_booked_days_NEW'] = 30 - final_summary_df['Next_30_to_60_days_available_days_NEW']\n",
    "\n",
    "# Recalculate 75% and 55% rules with NEW data\n",
    "# 75% rule: >22 booked days (with leniency=1, that's >21)\n",
    "final_summary_df['75_rule_met_NEW'] = final_summary_df['Next_30_days_booked_days_NEW'] > 21\n",
    "\n",
    "# 55% rule: >17 booked days (with leniency=2, that's >15)\n",
    "final_summary_df['55_rule_met_NEW'] = final_summary_df['Next_30_to_60_days_booked_days_NEW'] > 15\n",
    "\n",
    "preview_cols = [\n",
    "    'Room_id',\n",
    "\n",
    "    'Next_30_days_available_days_NEW', \n",
    "    'Next_30_days_booked_days_NEW', \n",
    "    \n",
    "    'Next_30_to_60_days_available_days_NEW', \n",
    "    'Next_30_to_60_days_booked_days_NEW', \n",
    "\n",
    "    '75_rule_met_NEW',\n",
    "    '55_rule_met_NEW',\n",
    "\n",
    "    'Next_30_days_booked_days',\n",
    "    'Next_30_to_60_days_booked_days',\n",
    "]\n",
    "\n",
    "final_summary_df['CHECK_NEXT_30'] = final_summary_df['Next_30_days_booked_days'] - final_summary_df['Next_30_days_booked_days_NEW']\n",
    "final_summary_df['CHECK_NEXT_30_TO_60'] = final_summary_df['Next_30_to_60_days_booked_days'] - final_summary_df['Next_30_to_60_days_booked_days_NEW']\n",
    "\n",
    "\n",
    "\n",
    "check_df = final_summary_df[[\n",
    "    'Room_id',\n",
    "    'CHECK_NEXT_30',\n",
    "    'CHECK_NEXT_30_TO_60'\n",
    "]]\n",
    "\n",
    "check_df[(~pd.isna(check_df['CHECK_NEXT_30'])) & (~pd.isna(check_df['CHECK_NEXT_30_TO_60'])) & (check_df['CHECK_NEXT_30'] != 0) & (check_df['CHECK_NEXT_30_TO_60'] != 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33fb066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate date ranges\n",
    "next_30_days_start = today\n",
    "next_30_days_end = today + timedelta(days=29)  # Days 0-29 (30 days total)\n",
    "\n",
    "next_31_to_60_start = today + timedelta(days=30)  # Day 30\n",
    "next_31_to_60_end = today + timedelta(days=59)    # Day 59 (30 days total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_dict = final_summary_df[final_summary_df['Room_id'] == 805725215071886985]['Available_dates_by_year_and_month'].values[0]\n",
    "\n",
    "print(\"next_30_days_start: \", next_30_days_start)\n",
    "print(\"next_30_days_end: \", next_30_days_end)\n",
    "\n",
    "count_available_days_in_range(dates_dict, next_30_days_start, next_30_days_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"next_31_to_60_start: \", next_31_to_60_start)\n",
    "print(\"next_31_to_60_end: \", next_31_to_60_end)\n",
    "\n",
    "count_available_days_in_range(dates_dict, next_31_to_60_start, next_31_to_60_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = final_summary_df[final_summary_df['Room_id'] == 1400836150848230066]\n",
    "\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3dc94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_summary_path = f\"Output-Summary-Data/{region_name}_results_grid_{1}_to_{100}.csv\"\n",
    "final_summary_df.to_csv(output_summary_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0571e07",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc0d62d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a3ff930",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ecb3109",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b578988",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f37d2aa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea8f2bcd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69eaf368",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90366c4d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560693ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================================\n",
    "# # PHASE 2: ENRICHMENT - Apply 75%/55% Rules & Review Analysis\n",
    "# # ============================================================================\n",
    "\n",
    "# # Set today's date for calculations\n",
    "# today = date.today()\n",
    "# COMPLETE_MONTHS_THIS_YEAR = set([m for m in range(1, today.month+1)])\n",
    "# COMPLETE_MONTHS_LAST_YEAR = set([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "\n",
    "# print(\"üî¨ Starting enrichment phase...\")\n",
    "# print(f\"Total discovered listings to process: {len(all_results)}\")\n",
    "# print(f\"Strategy: Only enrich listings that pass 75% rule\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# # Initialize summary DataFrame\n",
    "# summary_df = pd.DataFrame(columns=[\n",
    "#     'Room_id', 'Listing_url', \n",
    "#     'Next_30_days_booked_days', 'Next_30_to_60_days_booked_days',\n",
    "#     '75_rule_met', '55_rule_met',\n",
    "#     'Warning_level', 'Warning_type', 'Warning_message',\n",
    "#     'Rating', 'Review_count',\n",
    "#     'Review_months_this_year', 'Review_months_last_year',\n",
    "#     'Missing_review_months_this_year', 'Missing_review_months_last_year',\n",
    "#     'Total_missing_review_months_this_year', 'Total_missing_review_months_last_year',\n",
    "#     'Latitude', 'Longitude', 'Grid_index'\n",
    "# ])\n",
    "\n",
    "# # Process each discovered listing\n",
    "# listings_passed_75_rule = 0\n",
    "# listings_failed_75_rule = 0\n",
    "# enrichment_errors = []\n",
    "\n",
    "# for idx, result in enumerate(all_results):\n",
    "#     try:\n",
    "#         room_id = result['room_id']\n",
    "#         room_url = f\"https://www.airbnb.com.sg/rooms/{room_id}\"\n",
    "        \n",
    "#         if (idx + 1) % 10 == 0:\n",
    "#             print(f\"  Processing {idx + 1}/{len(all_results)}... (75% pass: {listings_passed_75_rule}, skip: {listings_failed_75_rule})\")\n",
    "#             # Add random delay every 10 listings to avoid rate limiting\n",
    "#             delay = random.uniform(2, 5)  # Random delay between 2-5 seconds\n",
    "#             # print(f\"  ‚è∏Ô∏è  Pausing for {delay:.1f}s to avoid rate limits...\")\n",
    "#             time.sleep(delay)\n",
    "        \n",
    "#         # Extract basic info\n",
    "#         # This is for Chicago\n",
    "#         if 'rating' not in result.keys():\n",
    "#             rating = result['raw_data']['rating']['value']\n",
    "#             review_count = result['raw_data']['rating']['reviewCount']\n",
    "#             latitude = result['raw_data']['coordinates']['latitude']\n",
    "#             longitude = result['raw_data']['coordinates']['longitud']\n",
    "#         else:\n",
    "#             rating = result['rating']['value']\n",
    "#             review_count = result['rating']['reviewCount']\n",
    "#             latitude = result['coordinates']['latitude']\n",
    "#             longitude = result['coordinates']['longitud']\n",
    "            \n",
    "#         grid_index = result.get('grid_index', None)\n",
    "        \n",
    "#         # Get calendar data (3 months)\n",
    "#         calendar_info = get_calendar(room_id=room_id)\n",
    "#         current_month_calendar = calendar_info[0]\n",
    "#         next_month_calendar = calendar_info[1]\n",
    "#         next_two_months_calendar = calendar_info[2]\n",
    "        \n",
    "#         curr_month_available_dates = get_available_dates(current_month_calendar)\n",
    "#         next_month_available_dates = get_available_dates(next_month_calendar)\n",
    "#         next_two_months_available_dates = get_available_dates(next_two_months_calendar)\n",
    "        \n",
    "#         # Check 75% rule (next 30 days, leniency=2)\n",
    "#         rule75_met, days_booked_next30days = check_75_rule(\n",
    "#             curr_month_available_dates=curr_month_available_dates,\n",
    "#             next_month_available_dates=next_month_available_dates,\n",
    "#             leniency=2\n",
    "#         )\n",
    "        \n",
    "#         # ONLY PROCESS IF 75% RULE IS MET\n",
    "#         if True:  # Get all info regardless of 75% rule\n",
    "#             if rule75_met:\n",
    "#                 listings_passed_75_rule += 1\n",
    "            \n",
    "#             # Check 55% rule (days 31-60, leniency=2)\n",
    "#             rule55_met, days_booked_nextnext30days = check_55_rule(\n",
    "#                 next_month_available_dates=next_month_available_dates,\n",
    "#                 next_two_months_available_dates=next_two_months_available_dates,\n",
    "#                 leniency=2\n",
    "#             )\n",
    "            \n",
    "#             # Get reviews data\n",
    "#             review_months = analyze_reviews(room_id)\n",
    "            \n",
    "#             if today.year in review_months:\n",
    "#                 review_months_this_year = review_months[today.year]\n",
    "#             else:\n",
    "#                 review_months_this_year = set()\n",
    "            \n",
    "#             if today.year - 1 in review_months:\n",
    "#                 review_months_last_year = review_months[today.year - 1]\n",
    "#             else:\n",
    "#                 review_months_last_year = set()\n",
    "            \n",
    "#             # Check review frequency (leniency=3)\n",
    "#             warning_level, warning_type, warning_message = check_reviews_count(\n",
    "#                 review_months_this_year=review_months_this_year,\n",
    "#                 review_months_last_year=review_months_last_year,\n",
    "#                 leniency=3\n",
    "#             )\n",
    "            \n",
    "#             missing_review_months_this_year = list(COMPLETE_MONTHS_THIS_YEAR - review_months_this_year)\n",
    "#             missing_review_months_last_year = list(COMPLETE_MONTHS_LAST_YEAR - review_months_last_year)\n",
    "            \n",
    "#             # Add to summary DataFrame\n",
    "#             new_row = pd.DataFrame([{\n",
    "#                 'Room_id': room_id,\n",
    "#                 'Listing_url': room_url,\n",
    "#                 'Next_30_days_booked_days': days_booked_next30days,\n",
    "#                 'Next_30_to_60_days_booked_days': days_booked_nextnext30days,\n",
    "#                 '75_rule_met': rule75_met,\n",
    "#                 '55_rule_met': rule55_met,\n",
    "#                 'Warning_level': warning_level,\n",
    "#                 'Warning_type': warning_type,\n",
    "#                 'Warning_message': warning_message,\n",
    "#                 'Rating': rating,\n",
    "#                 'Review_count': review_count,\n",
    "#                 'Review_months_this_year': list(review_months_this_year),\n",
    "#                 'Review_months_last_year': list(review_months_last_year),\n",
    "#                 'Missing_review_months_this_year': missing_review_months_this_year,\n",
    "#                 'Missing_review_months_last_year': missing_review_months_last_year,\n",
    "#                 'Total_missing_review_months_this_year': len(missing_review_months_this_year),\n",
    "#                 'Total_missing_review_months_last_year': len(missing_review_months_last_year),\n",
    "#                 'Latitude': latitude,\n",
    "#                 'Longitude': longitude,\n",
    "#                 'Grid_index': grid_index,\n",
    "#             }])\n",
    "            \n",
    "#             summary_df = pd.concat([summary_df, new_row], ignore_index=True)\n",
    "            \n",
    "#         else:\n",
    "#             # 75% rule not met - skip this listing\n",
    "#             listings_failed_75_rule += 1\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         error_msg = f\"Error processing room_id {result.get('room_id', 'unknown')}: {str(e)}\"\n",
    "#         print(f\"  ‚ö†Ô∏è {error_msg}\")\n",
    "#         enrichment_errors.append(error_msg)\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"‚úÖ ENRICHMENT COMPLETE\")\n",
    "# print(\"=\" * 70)\n",
    "# print(f\"Total discovered listings: {len(all_results)}\")\n",
    "# print(f\"Passed 75% rule (enriched): {listings_passed_75_rule}\")\n",
    "# print(f\"Failed 75% rule (skipped): {listings_failed_75_rule}\")\n",
    "# print(f\"Errors during enrichment: {len(enrichment_errors)}\")\n",
    "# print(f\"Final qualified listings: {len(summary_df)}\")\n",
    "# print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_filename = f\"./Output-Summary-Data/{region_name}_results_grid_{grid_start_index}_to_{grid_end_index}.csv\"\n",
    "# summary_df.to_csv(save_filename, index=False)\n",
    "# print(f\"Saved to: {save_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbbfca0",
   "metadata": {},
   "source": [
    "# Step 1: discovery all listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================================\n",
    "# # OPTION A: USE IMPROVED DISCOVERY SYSTEM (RECOMMENDED)\n",
    "# # ============================================================================\n",
    "\n",
    "# from discovery import discover_all_grids, DiscoveryConfig, BBox, AirbnbDiscoveryEngine\n",
    "\n",
    "# # Configure discovery parameters\n",
    "# discovery_config = DiscoveryConfig(\n",
    "#     # Rate limiting (conservative to avoid bans)\n",
    "#     requests_per_minute=12,\n",
    "    \n",
    "#     # Subdivision strategy\n",
    "#     max_results_before_subdivide=280,  # Subdivide if we hit ~280+ results (likely capped)\n",
    "#     min_bbox_size_degrees=0.001,  # Stop subdividing below ~100m\n",
    "#     max_subdivision_depth=4,\n",
    "    \n",
    "#     # Multi-pass strategy (catches rotated listings)\n",
    "#     num_discovery_passes=2,  # Run 3 passes with different date windows\n",
    "#     alternate_checkin_offsets=[14, 30],  # Try +14, +21, +30 days ahead\n",
    "\n",
    "#     # User-agent rotation (anti-detection)\n",
    "#     rotate_user_agents=True,\n",
    "    \n",
    "#     # Search parameters\n",
    "#     price_min=300,\n",
    "#     price_max=10000,\n",
    "#     currency=\"USD\",\n",
    "    \n",
    "#     # Caching for resume capability\n",
    "#     cache_dir=f\"Data/{region_name}/discovery_cache\",\n",
    "#     enable_cache=False,\n",
    "    \n",
    "#     # Stats output\n",
    "#     stats_file=f\"Data/{region_name}/discovery_stats.json\",\n",
    "# )\n",
    "\n",
    "# print(\"üîç Starting improved discovery system...\")\n",
    "# print(f\"Region: {region_name}\")\n",
    "# print(f\"Grid cells to search: {len(gird_coords_df)}\")\n",
    "# print(f\"Discovery passes per cell: {discovery_config.num_discovery_passes}\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# # Run discovery across all grids\n",
    "# discovered_listings, engine = discover_all_grids(gird_coords_df, region_name, discovery_config)\n",
    "\n",
    "# print(f\"\\n‚úÖ Discovery complete!\")\n",
    "# print(f\"üìä Total unique listings: {len(discovered_listings)}\")\n",
    "# print(f\"üìÅ Saved to: Data/{region_name}/discovered_listings.json\")\n",
    "# print(f\"üìà Stats saved to: {discovery_config.stats_file}\")\n",
    "\n",
    "# # Convert discoveries to format compatible with enrichment pipeline\n",
    "# all_results = [listing.raw_data for listing in discovered_listings.values()]\n",
    "# print(f\"\\n‚úì Ready for enrichment pipeline with {len(all_results)} listings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe882ca",
   "metadata": {},
   "source": [
    "# Step 2: run analysis based on the discovered listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb538b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================================\n",
    "# # PHASE 2: ENRICHMENT - Apply 75%/55% Rules & Review Analysis\n",
    "# # ============================================================================\n",
    "\n",
    "# # Set today's date for calculations\n",
    "# today = date.today()\n",
    "# COMPLETE_MONTHS_THIS_YEAR = set([m for m in range(1, today.month+1)])\n",
    "# COMPLETE_MONTHS_LAST_YEAR = set([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "\n",
    "# print(\"üî¨ Starting enrichment phase...\")\n",
    "# print(f\"Total discovered listings to process: {len(all_results)}\")\n",
    "# print(f\"Strategy: Only enrich listings that pass 75% rule\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# # Initialize summary DataFrame\n",
    "# summary_df = pd.DataFrame(columns=[\n",
    "#     'Room_id', 'Listing_url', \n",
    "#     'Next_30_days_booked_days', 'Next_30_to_60_days_booked_days',\n",
    "#     '75_rule_met', '55_rule_met',\n",
    "#     'Warning_level', 'Warning_type', 'Warning_message',\n",
    "#     'Rating', 'Review_count',\n",
    "#     'Review_months_this_year', 'Review_months_last_year',\n",
    "#     'Missing_review_months_this_year', 'Missing_review_months_last_year',\n",
    "#     'Total_missing_review_months_this_year', 'Total_missing_review_months_last_year',\n",
    "#     'Latitude', 'Longitude', 'Grid_index'\n",
    "# ])\n",
    "\n",
    "# # Process each discovered listing\n",
    "# listings_passed_75_rule = 0\n",
    "# listings_failed_75_rule = 0\n",
    "# enrichment_errors = []\n",
    "\n",
    "# for idx, result in enumerate(all_results):\n",
    "#     try:\n",
    "#         room_id = result['room_id']\n",
    "#         room_url = f\"https://www.airbnb.com.sg/rooms/{room_id}\"\n",
    "        \n",
    "#         if (idx + 1) % 10 == 0:\n",
    "#             print(f\"  Processing {idx + 1}/{len(all_results)}... (75% pass: {listings_passed_75_rule}, skip: {listings_failed_75_rule})\")\n",
    "#             # Add random delay every 10 listings to avoid rate limiting\n",
    "#             delay = random.uniform(2, 5)  # Random delay between 2-5 seconds\n",
    "#             # print(f\"  ‚è∏Ô∏è  Pausing for {delay:.1f}s to avoid rate limits...\")\n",
    "#             time.sleep(delay)\n",
    "        \n",
    "#         # Extract basic info\n",
    "#         rating = result['rating']['value']\n",
    "#         review_count = result['rating']['reviewCount']\n",
    "#         latitude = result['coordinates']['latitude']\n",
    "#         longitude = result['coordinates']['longitud']\n",
    "#         grid_index = result.get('grid_index', None)\n",
    "        \n",
    "#         # Get calendar data (3 months)\n",
    "#         calendar_info = get_calendar(room_id=room_id)\n",
    "#         current_month_calendar = calendar_info[0]\n",
    "#         next_month_calendar = calendar_info[1]\n",
    "#         next_two_months_calendar = calendar_info[2]\n",
    "        \n",
    "#         curr_month_available_dates = get_available_dates(current_month_calendar)\n",
    "#         next_month_available_dates = get_available_dates(next_month_calendar)\n",
    "#         next_two_months_available_dates = get_available_dates(next_two_months_calendar)\n",
    "        \n",
    "#         # Check 75% rule (next 30 days, leniency=2)\n",
    "#         rule75_met, days_booked_next30days = check_75_rule(\n",
    "#             curr_month_available_dates=curr_month_available_dates,\n",
    "#             next_month_available_dates=next_month_available_dates,\n",
    "#             leniency=2\n",
    "#         )\n",
    "        \n",
    "#         # ONLY PROCESS IF 75% RULE IS MET\n",
    "#         if rule75_met:\n",
    "#             listings_passed_75_rule += 1\n",
    "            \n",
    "#             # Check 55% rule (days 31-60, leniency=2)\n",
    "#             rule55_met, days_booked_nextnext30days = check_55_rule(\n",
    "#                 next_month_available_dates=next_month_available_dates,\n",
    "#                 next_two_months_available_dates=next_two_months_available_dates,\n",
    "#                 leniency=2\n",
    "#             )\n",
    "            \n",
    "#             # Get reviews data\n",
    "#             review_months = analyze_reviews(room_id)\n",
    "            \n",
    "#             if today.year in review_months:\n",
    "#                 review_months_this_year = review_months[today.year]\n",
    "#             else:\n",
    "#                 review_months_this_year = set()\n",
    "            \n",
    "#             if today.year - 1 in review_months:\n",
    "#                 review_months_last_year = review_months[today.year - 1]\n",
    "#             else:\n",
    "#                 review_months_last_year = set()\n",
    "            \n",
    "#             # Check review frequency (leniency=3)\n",
    "#             warning_level, warning_type, warning_message = check_reviews_count(\n",
    "#                 review_months_this_year=review_months_this_year,\n",
    "#                 review_months_last_year=review_months_last_year,\n",
    "#                 leniency=3\n",
    "#             )\n",
    "            \n",
    "#             missing_review_months_this_year = list(COMPLETE_MONTHS_THIS_YEAR - review_months_this_year)\n",
    "#             missing_review_months_last_year = list(COMPLETE_MONTHS_LAST_YEAR - review_months_last_year)\n",
    "            \n",
    "#             # Add to summary DataFrame\n",
    "#             new_row = pd.DataFrame([{\n",
    "#                 'Room_id': room_id,\n",
    "#                 'Listing_url': room_url,\n",
    "#                 'Next_30_days_booked_days': days_booked_next30days,\n",
    "#                 'Next_30_to_60_days_booked_days': days_booked_nextnext30days,\n",
    "#                 '75_rule_met': rule75_met,\n",
    "#                 '55_rule_met': rule55_met,\n",
    "#                 'Warning_level': warning_level,\n",
    "#                 'Warning_type': warning_type,\n",
    "#                 'Warning_message': warning_message,\n",
    "#                 'Rating': rating,\n",
    "#                 'Review_count': review_count,\n",
    "#                 'Review_months_this_year': list(review_months_this_year),\n",
    "#                 'Review_months_last_year': list(review_months_last_year),\n",
    "#                 'Missing_review_months_this_year': missing_review_months_this_year,\n",
    "#                 'Missing_review_months_last_year': missing_review_months_last_year,\n",
    "#                 'Total_missing_review_months_this_year': len(missing_review_months_this_year),\n",
    "#                 'Total_missing_review_months_last_year': len(missing_review_months_last_year),\n",
    "#                 'Latitude': latitude,\n",
    "#                 'Longitude': longitude,\n",
    "#                 'Grid_index': grid_index,\n",
    "#             }])\n",
    "            \n",
    "#             summary_df = pd.concat([summary_df, new_row], ignore_index=True)\n",
    "            \n",
    "#         else:\n",
    "#             # 75% rule not met - skip this listing\n",
    "#             listings_failed_75_rule += 1\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         error_msg = f\"Error processing room_id {result.get('room_id', 'unknown')}: {str(e)}\"\n",
    "#         print(f\"  ‚ö†Ô∏è {error_msg}\")\n",
    "#         enrichment_errors.append(error_msg)\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"‚úÖ ENRICHMENT COMPLETE\")\n",
    "# print(\"=\" * 70)\n",
    "# print(f\"Total discovered listings: {len(all_results)}\")\n",
    "# print(f\"Passed 75% rule (enriched): {listings_passed_75_rule}\")\n",
    "# print(f\"Failed 75% rule (skipped): {listings_failed_75_rule}\")\n",
    "# print(f\"Errors during enrichment: {len(enrichment_errors)}\")\n",
    "# print(f\"Final qualified listings: {len(summary_df)}\")\n",
    "# print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d8ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================================\n",
    "# # SAVE RESULTS TO EXCEL\n",
    "# # ============================================================================\n",
    "\n",
    "# output_filename = f\"Data/{region_name}_enriched_listings_75_55_rule.xlsx\"\n",
    "\n",
    "# print(f\"üíæ Saving results to Excel...\")\n",
    "# print(f\"   File: {output_filename}\")\n",
    "# print(f\"   Rows: {len(summary_df)}\")\n",
    "\n",
    "# summary_df.to_excel(output_filename, index=False)\n",
    "\n",
    "# print(f\"‚úÖ Saved successfully!\")\n",
    "# print()\n",
    "# print(\"üìä Summary DataFrame preview:\")\n",
    "# display(summary_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c956c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================================\n",
    "# # ANALYSIS: View Statistics on Enriched Listings\n",
    "# # ============================================================================\n",
    "\n",
    "# print(\"=\" * 70)\n",
    "# print(\"üìà ENRICHED LISTINGS ANALYSIS\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# if len(summary_df) > 0:\n",
    "#     print(f\"\\nüéØ Occupancy Rules:\")\n",
    "#     print(f\"   Listings meeting 75% rule: {summary_df['75_rule_met'].sum()} (100% - by design)\")\n",
    "#     print(f\"   Listings meeting 55% rule: {summary_df['55_rule_met'].sum()} ({100*summary_df['55_rule_met'].sum()/len(summary_df):.1f}%)\")\n",
    "    \n",
    "#     print(f\"\\nüìä Booking Statistics:\")\n",
    "#     print(f\"   Avg days booked (next 30 days): {summary_df['Next_30_days_booked_days'].mean():.1f}\")\n",
    "#     print(f\"   Avg days booked (days 31-60): {summary_df['Next_30_to_60_days_booked_days'].mean():.1f}\")\n",
    "    \n",
    "#     print(f\"\\n‚≠ê Rating Statistics:\")\n",
    "#     print(f\"   Avg rating: {summary_df['Rating'].mean():.2f}\")\n",
    "#     print(f\"   Avg review count: {summary_df['Review_count'].mean():.1f}\")\n",
    "    \n",
    "#     print(f\"\\n‚ö†Ô∏è Review Warnings:\")\n",
    "#     high_warnings = summary_df['Warning_level'].value_counts().get('High', 0)\n",
    "#     print(f\"   Listings with High warnings: {high_warnings} ({100*high_warnings/len(summary_df):.1f}%)\")\n",
    "    \n",
    "#     if high_warnings > 0:\n",
    "#         print(f\"\\n   Warning breakdown:\")\n",
    "#         warning_types = summary_df[summary_df['Warning_level'] == 'High']['Warning_type'].value_counts()\n",
    "#         for warning_type, count in warning_types.items():\n",
    "#             print(f\"     - {warning_type}: {count}\")\n",
    "    \n",
    "#     print(f\"\\nüóìÔ∏è Review Coverage:\")\n",
    "#     print(f\"   Avg months with reviews (this year): {summary_df['Review_months_this_year'].apply(len).mean():.1f}\")\n",
    "#     print(f\"   Avg months with reviews (last year): {summary_df['Review_months_last_year'].apply(len).mean():.1f}\")\n",
    "    \n",
    "# else:\n",
    "#     print(\"\\n‚ö†Ô∏è No listings passed the 75% rule!\")\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# today = date.today()\n",
    "# COMPLETE_MONTHS_THIS_YEAR = set([m for m in range(1, today.month+1)])\n",
    "# COMPLETE_MONTHS_LAST_YEAR = set([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a9745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_results_dir = f\"Data/{region_name}_search_all_results\"\n",
    "# warnings_dir = f\"Data/{region_name}_warnings\"\n",
    "\n",
    "# os.makedirs(search_results_dir, exist_ok=True)\n",
    "# os.makedirs(warnings_dir, exist_ok=True)\n",
    "\n",
    "# # Initialize warnings file\n",
    "# warnings_file = os.path.join(warnings_dir, \"search_all_warnings.txt\")\n",
    "# with open(warnings_file, 'w', encoding='utf-8') as f:\n",
    "#     f.write(\"=== Grid Index Mismatch Warnings ===\\n\")\n",
    "#     f.write(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "\n",
    "\n",
    "# all_results = []\n",
    "\n",
    "# for index, (ne_lat, ne_long, sw_lat, sw_long) in enumerate(bounding_boxes):\n",
    "#     grid_index = index + 1\n",
    "\n",
    "#     results = search_all(\n",
    "#         check_in=\"\",\n",
    "#         check_out= \"\",\n",
    "#         ne_lat=ne_lat, ne_long=ne_long,\n",
    "#         sw_lat=sw_lat, sw_long=sw_long,\n",
    "#         zoom_value=0, # zoom_value has no effect on the results\n",
    "#         price_min=300,\n",
    "#         price_max=10000,\n",
    "#         currency=\"USD\"\n",
    "#     )\n",
    "#     print(f\"Grid index {index} : Found {len(results)} results.\")\n",
    "    \n",
    "#     # Save each result as individual JSON files\n",
    "#     for result_idx, result in enumerate(results):\n",
    "\n",
    "#         room_id = result['room_id']\n",
    "#         res_lat = result['coordinates']['latitude']\n",
    "#         res_lon = result['coordinates']['longitud']\n",
    "#         grid_verify = find_grid_for_coordinate(res_lat, res_lon)\n",
    "\n",
    "#         if not grid_verify:\n",
    "#             warning = (f\"‚ö†Ô∏è Custom Error: Room ID ({room_id}) do not belong to any grid in gird_coords_df!!!!! latitude: {res_lat} and longitude: {res_lon}\")\n",
    "#             print(f\"\\n{warning}\\n\")\n",
    "\n",
    "#         if grid_verify != grid_index:\n",
    "#             warning = f\"‚ö†Ô∏è Custom Warning: Grid Number Mistmatch in room ID ({room_id}) : grid_index ({grid_index}) != grid_verify ({grid_verify}). !!!!!\\n grid_index is corrected to be {grid_verify}.\"\n",
    "#             print(f\"\\n{warning}\\n\")\n",
    "\n",
    "#             # Log warning to file\n",
    "#             with open(warnings_file, 'a', encoding='utf-8') as f:\n",
    "#                 f.write(f\"Grid {grid_index} -> {grid_verify}: Room ID {room_id} at ({res_lat}, {res_lon})\\n\")\n",
    "\n",
    "#             grid_index = grid_verify # Correct grid index\n",
    "\n",
    "#         result[\"grid_index\"] = grid_index\n",
    "#         filename = f\"grid_{grid_index}_listing_{room_id}.json\"\n",
    "#         filepath = os.path.join(search_results_dir, filename)\n",
    "        \n",
    "#         # try:\n",
    "#         #     with open(filepath, 'w', encoding='utf-8') as f:\n",
    "#         #         json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "#         # except Exception as e:\n",
    "#         #     print(f\"  Error saving {filename}: {e}\")\n",
    "\n",
    "#         all_results.append(result)\n",
    "    \n",
    "#     # all_results.extend(results)\n",
    "\n",
    "\n",
    "# # Add summary to warnings file\n",
    "# with open(warnings_file, 'a', encoding='utf-8') as f:\n",
    "#     f.write(f\"\\n=== Summary ===\\n\")\n",
    "#     f.write(f\"Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "#     f.write(f\"Total results processed: {len(all_results)}\\n\")\n",
    "\n",
    "\n",
    "# print(\"=\"*50)\n",
    "# print(f\"Total number of results: {len(all_results)}\")\n",
    "# print(f\"Results saved to: {search_results_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7b6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = search_results_dir\n",
    "# all_results = load_grid_json_files(folder_path)\n",
    "# print(f\"Loaded {len(all_results)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052fc20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chunked Processing Configuration\n",
    "# CHUNK_SIZE = 20\n",
    "# PROCESSED_DIR = \"Data/listing_analysis\"\n",
    "# PROGRESS_FILE = os.path.join(PROCESSED_DIR, \"progress.json\")\n",
    "\n",
    "# # Create directory for processed chunks\n",
    "# os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# def save_chunk(chunk_id, listings_data, failed_listings, start_idx, end_idx):\n",
    "#     \"\"\"Save a chunk of processed listings to JSON file\"\"\"\n",
    "#     chunk_data = {\n",
    "#         \"chunk_info\": {\n",
    "#             \"chunk_id\": chunk_id,\n",
    "#             \"start_index\": start_idx,\n",
    "#             \"end_index\": end_idx,\n",
    "#             \"processed_at\": datetime.now().isoformat(),\n",
    "#             \"total_listings\": len(listings_data) + len(failed_listings),\n",
    "#             \"successful_listings\": len(listings_data),\n",
    "#             \"failed_listings\": len(failed_listings)\n",
    "#         },\n",
    "#         \"listings\": listings_data,\n",
    "#         \"failed_listings\": failed_listings\n",
    "#     }\n",
    "    \n",
    "#     chunk_filename = f\"chunk_{chunk_id:03d}.json\"\n",
    "#     chunk_filepath = os.path.join(PROCESSED_DIR, chunk_filename)\n",
    "    \n",
    "#     try:\n",
    "#         with open(chunk_filepath, 'w', encoding='utf-8') as f:\n",
    "#             json.dump(chunk_data, f, indent=2, ensure_ascii=False)\n",
    "#         return True\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error saving chunk {chunk_id}: {e}\")\n",
    "#         return False\n",
    "\n",
    "\n",
    "\n",
    "# def update_progress(chunk_id, total_chunks):\n",
    "#     \"\"\"Update progress tracking file\"\"\"\n",
    "#     progress_data = {\n",
    "#         \"total_listings\": len(all_results),\n",
    "#         \"chunk_size\": CHUNK_SIZE,\n",
    "#         \"total_chunks\": total_chunks,\n",
    "#         \"completed_chunks\": list(range(chunk_id + 1)),\n",
    "#         \"current_chunk\": chunk_id,\n",
    "#         \"last_updated\": datetime.now().isoformat()\n",
    "#     }\n",
    "    \n",
    "#     try:\n",
    "#         with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:\n",
    "#             json.dump(progress_data, f, indent=2, ensure_ascii=False)\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ö†Ô∏è Warning: Could not update progress file: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# def load_progress():\n",
    "#     \"\"\"Load existing progress if available\"\"\"\n",
    "#     if os.path.exists(PROGRESS_FILE):\n",
    "#         try:\n",
    "#             with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:\n",
    "#                 return json.load(f)\n",
    "#         except Exception as e:\n",
    "#             print(f\"‚ö†Ô∏è Warning: Could not load progress file: {e}\")\n",
    "#     return None\n",
    "\n",
    "\n",
    "\n",
    "# def process_listing(result, idx):\n",
    "#     \"\"\"Process a single listing and return the result or error\"\"\"\n",
    "#     try:\n",
    "#         room_id = result['room_id']\n",
    "#         room_url = f\"https://www.airbnb.com.sg/rooms/{room_id}\"\n",
    "\n",
    "#         # print(f\"  Processing Index: {idx}, Room ID: {room_id}\")\n",
    "\n",
    "#         rating = result['rating']['value']\n",
    "#         review_count = result['rating']['reviewCount']\n",
    "#         latitude = result['coordinates']['latitude']\n",
    "#         longitude = result['coordinates']['longitud']\n",
    "#         grid_index = result['grid_index']\n",
    "        \n",
    "#         calendar_info = get_calendar(room_id=room_id)\n",
    "#         current_month_calendar = calendar_info[0]\n",
    "#         next_month_calendar = calendar_info[1]\n",
    "#         next_two_months_calendar = calendar_info[2]\n",
    "\n",
    "#         curr_month_available_dates = get_available_dates(current_month_calendar)\n",
    "#         next_month_available_dates = get_available_dates(next_month_calendar)\n",
    "#         next_two_months_available_dates = get_available_dates(next_two_months_calendar)\n",
    "\n",
    "#         rule75_met, days_booked_next30days = check_75_rule(\n",
    "#             curr_month_available_dates = curr_month_available_dates, \n",
    "#             next_month_available_dates = next_month_available_dates,\n",
    "#             leniency=2\n",
    "#         )\n",
    "\n",
    "#         rule55_met, days_booked_nextnext30days = check_55_rule(\n",
    "#             next_month_available_dates = next_month_available_dates,\n",
    "#             next_two_months_available_dates = next_two_months_available_dates,\n",
    "#             leniency=2\n",
    "#         )\n",
    "\n",
    "#         # Only process if 75 rule is met\n",
    "#         if rule75_met:\n",
    "#             review_months = analyze_reviews(room_id)\n",
    "\n",
    "#             if today.year in review_months:\n",
    "#                 review_months_this_year = review_months[today.year]\n",
    "#             else:\n",
    "#                 review_months_this_year = set()\n",
    "\n",
    "#             if today.year - 1 in review_months:\n",
    "#                 review_months_last_year = review_months[today.year - 1]\n",
    "#             else:\n",
    "#                 review_months_last_year = set()\n",
    "\n",
    "#             # Review count check\n",
    "#             warning_level, warning_type, warning_message = check_reviews_count(\n",
    "#                 review_months_this_year = review_months_this_year,\n",
    "#                 review_months_last_year = review_months_last_year, \n",
    "#                 leniency=3\n",
    "#             )\n",
    "\n",
    "#             missing_review_months_this_year = list(COMPLETE_MONTHS_THIS_YEAR - review_months_this_year) \n",
    "#             missing_review_months_last_year = list(COMPLETE_MONTHS_LAST_YEAR - review_months_last_year)\n",
    "\n",
    "#             listing_data = {\n",
    "#                 \"room_id\": room_id,\n",
    "#                 \"listing_url\": room_url,\n",
    "#                 \"next_30_days_booked_days\": days_booked_next30days,\n",
    "#                 \"next_30_to_60_days_booked_days\": days_booked_nextnext30days,\n",
    "#                 \"rule_75_met\": rule75_met,\n",
    "#                 \"rule_55_met\": rule55_met,\n",
    "#                 \"warning_level\": warning_level,\n",
    "#                 \"warning_type\": warning_type,\n",
    "#                 \"warning_message\": warning_message,\n",
    "#                 \"rating\": rating,\n",
    "#                 \"review_count\": review_count,\n",
    "#                 \"review_months_this_year\": list(review_months_this_year),\n",
    "#                 \"review_months_last_year\": list(review_months_last_year),\n",
    "#                 \"missing_review_months_this_year\": missing_review_months_this_year,\n",
    "#                 \"missing_review_months_last_year\": missing_review_months_last_year,\n",
    "#                 \"total_missing_review_months_this_year\": len(missing_review_months_this_year),\n",
    "#                 \"total_missing_review_months_last_year\": len(missing_review_months_last_year),\n",
    "#                 \"latitude\": latitude,\n",
    "#                 \"longitude\": longitude,\n",
    "#                 \"grid_index\": grid_index,\n",
    "                \n",
    "#                 \"processing_status\": \"success\"\n",
    "#             }\n",
    "            \n",
    "#             return listing_data, None\n",
    "#         else:\n",
    "#             return None, None  # Skip listings that don't meet 75 rule\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         error_data = {\n",
    "#             \"room_id\": result.get('room_id', f'unknown_{idx}'),\n",
    "#             \"error_message\": str(e),\n",
    "#             \"processing_status\": \"failed\"\n",
    "#         }\n",
    "#         return None, error_data\n",
    "\n",
    "# print(f\"üìÅ Processing directory: {PROCESSED_DIR}\")\n",
    "# print(f\"üìä Total listings to process: {len(all_results)}\")\n",
    "# print(f\"üì¶ Chunk size: {CHUNK_SIZE}\")\n",
    "# print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb36fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_df = pd.DataFrame()\n",
    "# summary_df['Room_id'] = np.NaN\n",
    "# summary_df['Listing_url'] = np.NaN\n",
    "\n",
    "# summary_df['Next_30_days_booked_days'] = np.NaN\n",
    "# summary_df['Next_30_to_60_days_booked_days'] = np.NaN\n",
    "# summary_df['75_rule_met'] = False\n",
    "# summary_df['55_rule_met'] = False\n",
    "\n",
    "# summary_df['Warning_level'] = np.NaN\n",
    "# summary_df['Warning_type'] = np.NaN\n",
    "# summary_df['Warning_message'] = np.NaN\n",
    "\n",
    "# summary_df['Rating'] = np.NaN\n",
    "# summary_df['Review_count'] = np.NaN\n",
    "\n",
    "# summary_df['Review_months_this_year'] = []\n",
    "# summary_df['Review_months_last_year'] = []\n",
    "# summary_df['Missing_review_months_this_year'] = []\n",
    "# summary_df['Missing_review_months_last_year'] = []\n",
    "# summary_df['Total_missing_review_months_this_year'] = np.NaN\n",
    "# summary_df['Total_missing_review_months_last_year'] = np.NaN\n",
    "\n",
    "# summary_df['Latitiude'] = []\n",
    "# summary_df['Longitude'] = []\n",
    "\n",
    "# summary_df['Grid_index'] = np.NaN\n",
    "\n",
    "# summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Main Chunked Processing Loop\n",
    "\n",
    "# total_listings = len(all_results)\n",
    "# total_chunks = (total_listings + CHUNK_SIZE - 1) // CHUNK_SIZE  # Ceiling division\n",
    "\n",
    "# print(f\"Starting chunked processing...\")\n",
    "# print(f\"Total listings: {total_listings}\")\n",
    "# print(f\"Total chunks: {total_chunks}\")\n",
    "# print(f\"Output directory: {PROCESSED_DIR}\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# # Load existing progress if available\n",
    "# # progress = load_progress()\n",
    "\n",
    "# start_chunk = 0\n",
    "\n",
    "# # Process each chunk\n",
    "# for chunk_id in range(start_chunk, total_chunks):\n",
    "#     print(f\"Processing Chunk {chunk_id + 1}/{total_chunks}\")\n",
    "    \n",
    "#     start_idx = chunk_id * CHUNK_SIZE\n",
    "#     end_idx = min(start_idx + CHUNK_SIZE, total_listings)\n",
    "#     chunk_listings = all_results[start_idx:end_idx]\n",
    "        \n",
    "#     chunk_results = []\n",
    "#     chunk_errors = []\n",
    "    \n",
    "#     # Process each listing in the chunk\n",
    "#     for i, result in enumerate(chunk_listings):\n",
    "#         listing_idx = start_idx + i\n",
    "#         listing_data, error_data = process_listing(result, listing_idx)\n",
    "        \n",
    "#         if listing_data:\n",
    "#             chunk_results.append(listing_data)\n",
    "#         elif error_data:\n",
    "#             chunk_errors.append(error_data)\n",
    "    \n",
    "#     # Save chunk results\n",
    "#     success = save_chunk(chunk_id, chunk_results, chunk_errors, start_idx, end_idx-1)\n",
    "    \n",
    "#     if success:\n",
    "#         update_progress(chunk_id, total_chunks)\n",
    "#     else:\n",
    "#         break\n",
    "    \n",
    "#     # Progress summary\n",
    "#     total_processed = (chunk_id + 1) * CHUNK_SIZE\n",
    "#     if total_processed > total_listings:\n",
    "#         total_processed = total_listings\n",
    "    \n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"üéâ Chunked processing completed!\")\n",
    "# print(f\"üìÅ Results saved in: {PROCESSED_DIR}\")\n",
    "# print(f\"üìã Progress file: {PROGRESS_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43788bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Consolidate all chunks into final Excel file\n",
    "# def consolidate_chunks_to_excel():\n",
    "#     \"\"\"Combine all chunk JSON files into a single Excel file\"\"\"\n",
    "#     print(\"üîÑ Consolidating chunks into Excel file...\")\n",
    "    \n",
    "#     all_consolidated_data = []\n",
    "#     total_chunks_processed = 0\n",
    "#     total_listings_consolidated = 0\n",
    "    \n",
    "#     # Get all chunk files\n",
    "#     chunk_files = [f for f in os.listdir(PROCESSED_DIR) if f.startswith('chunk_') and f.endswith('.json')]\n",
    "#     chunk_files.sort()  # Sort to process in order\n",
    "    \n",
    "#     print(f\"üìÅ Found {len(chunk_files)} chunk files to consolidate\")\n",
    "    \n",
    "#     for chunk_file in chunk_files:\n",
    "#         chunk_filepath = os.path.join(PROCESSED_DIR, chunk_file)\n",
    "        \n",
    "#         try:\n",
    "#             with open(chunk_filepath, 'r', encoding='utf-8') as f:\n",
    "#                 chunk_data = json.load(f)\n",
    "            \n",
    "#             # Extract listings from chunk\n",
    "#             listings = chunk_data.get('listings', [])\n",
    "#             all_consolidated_data.extend(listings)\n",
    "            \n",
    "#             total_chunks_processed += 1\n",
    "#             total_listings_consolidated += len(listings)\n",
    "            \n",
    "#             print(f\"  ‚úÖ Processed {chunk_file}: {len(listings)} listings\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"  ‚ùå Error processing {chunk_file}: {e}\")\n",
    "    \n",
    "#     if all_consolidated_data:\n",
    "#         # Create DataFrame\n",
    "#         consolidated_df = pd.DataFrame(all_consolidated_data)\n",
    "        \n",
    "#         # Save to Excel\n",
    "#         output_filename = \"airbnb_dataset_75_55_rule_met_consolidated.xlsx\"\n",
    "#         output_filepath = os.path.join(PROCESSED_DIR, output_filename)\n",
    "        \n",
    "#         consolidated_df.to_excel(output_filepath, index=False)\n",
    "        \n",
    "#         print(f\"\\nüéâ Consolidation completed!\")\n",
    "#         print(f\"üìä Total chunks processed: {total_chunks_processed}\")\n",
    "#         print(f\"üìä Total listings consolidated: {total_listings_consolidated}\")\n",
    "#         print(f\"üìÅ Output file: {output_filepath}\")\n",
    "        \n",
    "#         return consolidated_df\n",
    "#     else:\n",
    "#         print(\"‚ùå No data found to consolidate\")\n",
    "#         return None\n",
    "\n",
    "# # Run consolidation\n",
    "# final_df = consolidate_chunks_to_excel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_df.to_excel(\"airbnb_dataset_75_55_rule_met.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f1e0c",
   "metadata": {},
   "source": [
    "# Target Specific Regions Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e49b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grd_id = 372\n",
    "\n",
    "# # target_coords = gird_coords_df[gird_coords_df['grid_id'] == grd_id]\n",
    "\n",
    "# # gird_target = target_coords['grid_id'].values[0]\n",
    "# # ne_lat_target = target_coords['ne_lat'].values[0]\n",
    "# # ne_long_target = target_coords['ne_long'].values[0]\n",
    "# # sw_lat_target = target_coords['sw_lat'].values[0]\n",
    "# # sw_long_target = target_coords['sw_long'].values[0]\n",
    "\n",
    "\n",
    "\n",
    "# ne_lat_target, ne_long_target = 41.95433, -87.646\n",
    "# sw_lat_target, sw_long_target = 41.94067, -87.674\n",
    "\n",
    "# print(\"Target Region Searching ...\")\n",
    "# target_results = search_all(\n",
    "#     check_in=\"\",\n",
    "#     check_out= \"\",\n",
    "#     ne_lat=ne_lat_target, ne_long=ne_long_target,\n",
    "#     sw_lat=sw_lat_target, sw_long=sw_long_target,\n",
    "#     zoom_value=10, # zoom_value has no effect on the results\n",
    "#     price_min=300,\n",
    "#     price_max=10000,\n",
    "#     currency=\"USD\"\n",
    "# )\n",
    "# print(f\"Found {len(target_results)} results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92201d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_target_listings(target_results):\n",
    "#     for result in target_results:\n",
    "#         room_id = result['room_id']\n",
    "#         room_url = f\"https://www.airbnb.com.sg/rooms/{room_id}\"\n",
    "\n",
    "#         print(f\"  Processing Index: {idx}, Room ID: {room_id}\")\n",
    "\n",
    "#         rating = result['rating']['value']\n",
    "#         review_count = result['rating']['reviewCount']\n",
    "#         latitude = result['coordinates']['latitude']\n",
    "#         longitude = result['coordinates']['longitud']\n",
    "#         grid_index = result['grid_index']\n",
    "        \n",
    "#         calendar_info = get_calendar(room_id=room_id)\n",
    "#         current_month_calendar = calendar_info[0]\n",
    "#         next_month_calendar = calendar_info[1]\n",
    "#         next_two_months_calendar = calendar_info[2]\n",
    "\n",
    "#         curr_month_available_dates = get_available_dates(current_month_calendar)\n",
    "#         next_month_available_dates = get_available_dates(next_month_calendar)\n",
    "#         next_two_months_available_dates = get_available_dates(next_two_months_calendar)\n",
    "\n",
    "#         rule75_met, days_booked_next30days = check_75_rule(\n",
    "#             curr_month_available_dates = curr_month_available_dates, \n",
    "#             next_month_available_dates = next_month_available_dates,\n",
    "#             leniency=2\n",
    "#         )\n",
    "\n",
    "#         rule55_met, days_booked_nextnext30days = check_55_rule(\n",
    "#             next_month_available_dates = next_month_available_dates,\n",
    "#             next_two_months_available_dates = next_two_months_available_dates,\n",
    "#             leniency=2\n",
    "#         )\n",
    "\n",
    "#         # Only process if 75 rule is met\n",
    "#         if rule75_met:\n",
    "#             review_months = analyze_reviews(room_id)\n",
    "\n",
    "#             if today.year in review_months:\n",
    "#                 review_months_this_year = review_months[today.year]\n",
    "#             else:\n",
    "#                 review_months_this_year = set()\n",
    "\n",
    "#             if today.year - 1 in review_months:\n",
    "#                 review_months_last_year = review_months[today.year - 1]\n",
    "#             else:\n",
    "#                 review_months_last_year = set()\n",
    "\n",
    "#             # Review count check\n",
    "#             warning_level, warning_type, warning_message = check_reviews_count(\n",
    "#                 review_months_this_year = review_months_this_year,\n",
    "#                 review_months_last_year = review_months_last_year, \n",
    "#                 leniency=3\n",
    "#             )\n",
    "\n",
    "#             missing_review_months_this_year = list(COMPLETE_MONTHS_THIS_YEAR - review_months_this_year) \n",
    "#             missing_review_months_last_year = list(COMPLETE_MONTHS_LAST_YEAR - review_months_last_year)\n",
    "\n",
    "#             listing_data = {\n",
    "#                 \"room_id\": room_id,\n",
    "#                 \"listing_url\": room_url,\n",
    "#                 \"next_30_days_booked_days\": days_booked_next30days,\n",
    "#                 \"next_30_to_60_days_booked_days\": days_booked_nextnext30days,\n",
    "#                 \"rule_75_met\": rule75_met,\n",
    "#                 \"rule_55_met\": rule55_met,\n",
    "#                 \"warning_level\": warning_level,\n",
    "#                 \"warning_type\": warning_type,\n",
    "#                 \"warning_message\": warning_message,\n",
    "#                 \"rating\": rating,\n",
    "#                 \"review_count\": review_count,\n",
    "#                 \"review_months_this_year\": list(review_months_this_year),\n",
    "#                 \"review_months_last_year\": list(review_months_last_year),\n",
    "#                 \"missing_review_months_this_year\": missing_review_months_this_year,\n",
    "#                 \"missing_review_months_last_year\": missing_review_months_last_year,\n",
    "#                 \"total_missing_review_months_this_year\": len(missing_review_months_this_year),\n",
    "#                 \"total_missing_review_months_last_year\": len(missing_review_months_last_year),\n",
    "#                 \"latitude\": latitude,\n",
    "#                 \"longitude\": longitude,\n",
    "#                 \"grid_index\": grid_index,\n",
    "                \n",
    "#                 \"processing_status\": \"success\"\n",
    "#             }\n",
    "            \n",
    "#             return listing_data, None\n",
    "#         else: return None, None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
